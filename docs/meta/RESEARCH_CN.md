# 报告

## 流行的 Agent Workflow 平台与框架

### 主流开源框架（全球）

-   **LangChain**（Python 和 JavaScript；GitHub 星标数约 70k）——LangChain 是最早且最受欢迎的 LLM 应用开发库之一。它引入了“链”（一系列提示词/LLM 调用）和“代理”（使用工具的 LLM）等抽象概念，用于创建具有上下文感知能力的推理应用。LangChain 支持广泛的集成（多个 LLM 提供商、向量数据库、API 等），并拥有丰富的生态系统（如用于监控的 LangSmith）。其多功能性以及对检索增强生成（RAG）、记忆和工具的集成，使其在各种 LLM 用例中得到广泛应用。
-   **LlamaIndex**（Python；GitHub 星标数约 30k）——LlamaIndex（前身为 GPT Index）专注于**检索增强生成（RAG）** 工作流。它提供数据连接器和索引结构，用于摄入文档并让 LLM 高效查询这些文档。开发者可以构建这样的管道：将用户查询映射到相关数据片段（通过索引），再将这些片段输入到 LLM 提示词中。LlamaIndex 与 LangChain 和各种向量存储无缝集成，专门适用于知识密集型应用。
-   **Haystack**（Python；GitHub 星标数约 25k）——deepset 开发的 Haystack 是一个成熟的开源框架，最初为神经搜索和问答而构建，现在已扩展到生成式 AI 管道。它采用以管道为中心的方法：你可以定义用于查询、过滤、阅读器（LLM）等的节点，并将它们链接起来。Haystack 在构建基于文档的生产级问答系统方面表现出色，拥有强大的评估工具，并支持混合搜索（关键词+向量）。它还支持提示词模板和生成组件，适用于基于检索的问答和开放式问答任务。
-   **Guidance**（Python；微软/OpenAI）——Guidance 是一个通过模板语言实现对 LLM 生成过程精细控制的框架。它允许在单个提示词模板中混合 prose、模型调用和 Python 逻辑，引导 LLM 生成结构化输出或遵循特定约束。Guidance 可以通过验证流式输出的部分内容，强制生成 JSON 格式或标签。这让开发者能更确定性地控制 LLM 的推理步骤和输出格式，而这在较简单的框架中通常是隐式处理的（例如，你可以通过模板定义并在循环中验证，确保 LLM 的回答包含特定字段）。
-   **AutoGen**（Python；GitHub 星标数约 55k）——AutoGen 是微软开源的用于创建**多代理对话**和工作流的框架。它支持定义多个 LLM“代理”（具有助手、用户代理、工具等角色），这些代理通过相互对话解决任务。AutoGen 提供了更高层次的模式，使代理能够协作或专业化（例如，一个代理可以作为推理规划器，另一个作为执行者）。它还支持工具集成，并具有**AutoGen Studio**图形界面，用于可视化和原型化代理对话。AutoGen 在处理异步交互方面表现出色（代理可以并发工作），并能确保代理可靠地使用工具。其对多代理编排的专注使其迅速获得普及，因为开发者正积极探索基于代理的 AI 工作流。
-   **CrewAI**（Python；GitHub 星标数约 45k）——CrewAI 是一个较新的框架，专为**协作式多代理系统**设计。它从零开始构建（不基于 LangChain），旨在让多个专业化代理（“团队成员”）协作处理复杂任务。CrewAI 强调高性能和精细控制：它允许对代理行为进行底层定制，并采用事件驱动架构（其“流程”和“团队”抽象）实现灵活编排。该项目突出企业级功能（可观测性、用于监控部署的可选控制平面），并声称拥有快速增长的开发者社区。CrewAI 的兴起反映了多代理自主性的趋势，尤其适用于需要**自主性和协调性**的复杂企业工作流。
-   **Flowise**（TypeScript/Node；GitHub 星标数约 42k）——Flowise 是一个开源**低代码**工具，通过可视化**拖放界面**构建 LLM 应用。它提供基于节点的画布，每个节点可以是 LLM 提示词、工具（如网页搜索、数据库查询）、条件逻辑等，你可以通过连接节点设计工作流。Flowise 作为 Web 应用运行，并使用底层引擎（部分节点基于 LangChain JS）执行这些流程。它支持许多 LLM 提供商，只需最少的代码即可实现链式调用，非常适合快速原型开发。不过，Flowise 目前专注于线性流程，默认**不支持代理式工具使用（无动态 ReAct 代理）**。它适用于简单的聊天机器人、数据查询工作流和其他确定性管道，但如需代理式工具选择，可能需要集成其他方法。
-   **LangFlow**（Python + React；GitHub 星标数约 80k）——LangFlow 提供了一个精致的界面，用于可视化构建和部署基于 LangChain 组件的 LLM 工作流。与 Flowise 类似，它提供图形编辑器，你可以在其中拖放提示词、链、记忆、工具等节点，再通过连接节点定义应用逻辑。LangFlow 支持所有主流 LLM 和向量数据库，并能将流程**导出为 JSON 或 Python 代码**供应用使用。值得注意的是，它内置支持多代理编排和对话管理。LangFlow 的一个强大功能是，你创建的每个流程都可以转换为**端点或微服务**——它包含 API 服务器来托管工作流，供外部应用调用。得益于活跃的社区和易用性，LangFlow 的代码仓库星标数迅速增长到数万个，成为 LLM 应用的首选无代码构建工具之一。
-   **SuperAGI**（Python；GitHub 星标数约 6k）——SuperAGI 是一个专注于自主 AI 代理的开源框架（类似于“AutoGPT”）。它提供一个平台来创建可执行多步骤任务、使用工具并尝试实现用户设定目标的代理。SuperAGI 包含用于管理代理的 Web 界面和处理规划与工具集成的执行引擎（网页浏览、文件 I/O 等）。虽然尚未达到 LangChain 的普及度，但它通过承诺更“以开发者为中心”的自主代理方法（强调可靠性和可扩展性）吸引了关注。截至 2023 年中期，它拥有约 6k 星标，并在社区中引发了一定热度。如果你的用例倾向于具有记忆的长期运行代理，且希望有现成的起点而非通过 LangChain 组装组件，SuperAGI 会是一个选择。
-   **Marvin**（Python；GitHub 星标数 2025 年约 3k）——Marvin 是一个较新的库（由 PrefectHQ 团队开发），用于构建 AI 驱动的软件，强调**结构化输出和可靠性**。Marvin 允许在 Python 中定义“AI 函数”，包括其返回类型的 schema（使用 Pydantic 数据模型）。在运行时，它负责调用 LLM 并将 LLM 的输出解析/验证为指定的 Pydantic schema，必要时自动重试或修正。这让开发者能将 LLM 调用更像具有类型返回的常规函数——使 AI 的行为更具确定性和可测试性。Marvin 也支持工具和类代理工作流，但其突出特点是将输出验证以开发者友好的方式集成。它是一个专注于“可信输出”而非仅调用链的框架示例。

（以上列表并非详尽——其他值得一提的包括 Hugging Face 的**Transformers**管道（提供文本生成和问答的基本构建块）、用于评估/监控的**OpenAI Evals**和**LangSmith**、微软的实验性**TypeChat**（用于 Zod 结构化输出的 TypeScript 库）等。该生态系统正在快速发展，新框架不断涌现。）

### 国内平台与框架（中国）

中国 AI 社区已开发出丰富的 LLM 应用平台——包括开源项目和企业解决方案——以满足国内需求（如支持中文语言模型、自托管和数据隐私要求）。以下我们重点介绍几个知名示例：

-   **Dify**（开源；Python/TypeScript；GitHub 星标数 10 万+）——Dify 是一个生产级开源 LLM 应用开发平台。它提供**直观的 Web 界面**和结合 LLMOps 与“后端即服务”能力的全面后端。借助 Dify，开发者（或非开发者）可以通过在画布上创建**工作流**（包含模型提示词、工具调用和分支）可视化构建 AI 应用。它通过类插件的提供商系统支持数百个 LLM（专有和开源）——包括 GPT-4、Mistral、Llama 3、百川等——并允许混合使用本地和 API 托管模型。关键是，Dify 内置支持检索增强生成：只需几步即可摄入文档并设置**RAG 管道**（从文档摄入到问答）。它还支持通过 OpenAI 函数调用或 ReAct 提示词定义**代理**，并提供 50 多个现成工具（网页搜索、计算器、图像生成器等）供代理使用。对于生产部署，Dify 提供提示词监控/日志、用户管理和团队协作等功能。得益于强大的社区采用，截至 2025 年中期，Dify 的 GitHub 仓库星标数突破**10 万**，成为全球顶级开源 AI 项目之一。Dify 的流行凸显了对可自托管的集成式、用户友好型 LLM 开发平台的需求——尤其对于关注数据治理的企业。（注：Dify 由初创公司 LangGenius 开发，既有开源版本也有托管云服务。它体现了“低代码”AI 平台如何加速开发，同时仍通过 API 提供可扩展性。）
-   **Eino**（开源；Go；GitHub 星标数约 5k）——Eino 是字节跳动 2024 年开源的大型语言模型应用框架。基于 Golang 开发，它旨在成为“全代码”开发者框架（而非无代码平台），强调生产服务的类型安全、可组合性和性能。Eino 借鉴了 LangChain 和 LlamaIndex 等框架的灵感，但设计了符合 Go 约定和性能需求的 API。它提供一组**可重用组件**（LLM 接口、提示词模板、向量存储、工具等）和强大的**组合引擎**用于编排。值得注意的是，Eino 支持构建简单的线性链和更复杂的有向操作图（包括循环和分支）。这允许开发者以结构化方式创建非平凡的代理循环和工具使用工作流，由框架处理并发和数据流。它还包括对这些链/图的强**类型检查**（编译时），以防止许多错误。尽管 Eino 相对较新，星标数（约 5k）反映出其社区较小众，但作为在系统编程环境（Go）中验证 LLM 编排的项目，它具有重要意义。这也表明大型科技公司（字节跳动）对开源其内部 LLMOps 工具的兴趣。对于 Go 开发者或高性能服务器场景，Eino 提供了一个有趣的替代 Python 框架的选择。
-   **Promptulate**（开源；Python；社区规模较小）——Promptulate 是百度千帆社区开发者创建的轻量级 Python 框架，旨在简化 LLM**代理**和自动化构建。它允许以“Pythonic”方式构建代理，用最少的样板代码指定工具和行为。Promptulate 的设计有点类似专注于代理用例的迷你 LangChain。虽然其 GitHub 影响力有限（几百个星标），但作为国内围绕 LLM 的开源创新之一，它值得关注。它支持百度的文心一言和其他本地模型，使中国开发者更容易将这些模型集成到代理循环中。
-   **企业云平台**——除开源项目外，中国科技巨头在云上发布了全面的 LLM 开发平台：
    -   阿里云的“百川”或“百炼”AI 平台——阿里云上的企业级套件，用于构建和部署大模型应用。它提供从模型训练、微调到应用托管的端到端工具。百炼集成了阿里自己的模型（如通义千问），并提供无代码界面用于链式模型调用，专注于企业用例（客户服务、内容生成等）。它强调数据安全和与其他阿里云服务的轻松集成。
    -   百度千帆平台——百度的一站式大模型开发和服务平台，支持其文心大模型等。千帆允许开发者进行提示词工程、在自定义数据上微调模型，并通过 API 部署。它还推出了无代码提示词/界面构建器（有点类似 OpenAI 的 ChatGPT 插件界面或微软 Prompt Flow），以加速聊天机器人创建。百度的生态系统方法意味着千帆与他们的搜索、云和生产力应用相连接。
    -   华为——华为的**MindSpore**框架（AI 训练框架）和相关的**盘古**大模型，辅以 2023 年推出的应用开发平台（昇腾 AI 云服务）。华为的平台面向需要本地解决方案的行业（金融、制造业等），提供从模型训练到部署的完整管道，强调利用华为硬件（昇腾 AI 芯片）。虽然公开可访问性较低，但它满足了出于数据主权考虑对**自主国内 AI 解决方案**的需求。

这些国内平台通常与西方同类产品（如 Azure OpenAI Studio 或 AWS Bedrock）功能相似，但具有本地模型支持和符合中国法规的特点。它们并非都是开源的，但对企业采用至关重要。值得注意的是，开源项目 Dify 已定位为**国内替代 OpenAI 即将推出的 GPTs/Assistants 平台或 LangChain**的选择，其可视化工作流设计、集成向量数据库和一键部署等功能与中国企业需求高度契合。Dify（10 万+星标）和 LangFlow（数万星标）在社区的快速崛起表明，开发者重视能够弥合复杂 LLM 能力与实际应用需求之间差距的易用工具。

#### 主要 LLM 开发工具对比

下表对上述框架和平台进行了高层级对比，总结了它们的核心属性：

| **名称**         | **类型与许可证**         | **主要语言**                     | **GitHub 星标数** | **核心功能与能力**                                                                                                                                                     |
| ---------------- | ------------------------ | -------------------------------- | ----------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **LangChain**    | 库（开源，MIT）          | Python；JS/TS                    | ~70k              | 提示词与工具链；广泛集成（LLM、向量数据库、API）；支持 RAG、记忆、代理（ReAct）；大型社区/生态系统。                                                                   |
| **LlamaIndex**   | 库（开源）               | Python                           | ~30k              | RAG 数据框架；文档索引；高效检索和分块；与 LangChain 和各种数据库轻松集成。                                                                                            |
| **Haystack**     | 框架（开源，Apache）     | Python                           | ~25k              | 问答/搜索模块化管道；支持混合搜索和生成式问答；评估工具；生产就绪（用于许多 NLP 应用）。                                                                               |
| **Guidance**     | 库（开源）               | Python                           | ~4k（估计）       | 用于精细控制 LLM 输出的模板；可通过部分验证强制格式；适用于结构化提示编程。                                                                                            |
| **AutoGen**      | 框架（开源，MIT）        | Python                           | ~55k              | 多代理对话；具有角色专业化的代理团队；工具集成；支持异步和并发代理；附带 GUI（AutoGen Studio）。                                                                       |
| **CrewAI**       | 框架（开源）             | Python                           | ~45k              | 高性能多代理框架；自定义“团队”和“流程”抽象；独立于 LangChain；企业功能（可观测性、控制平面）；强调协作代理。                                                           |
| **Flowise**      | 低代码平台（开源）       | TypeScript/Node                  | ~42k              | 可视化拖放构建器；通过 API 支持许多 LLM；适用于线性工作流和聊天机器人；**无**原生代理/工具循环（无动态决策）；易于通过 Docker 部署。                                   |
| **LangFlow**     | 低代码平台（开源，MIT）  | Python（FastAPI）+ TS（React）   | ~80k              | LangChain 流程可视化界面；支持多代理和 RAG 设置；可将流程部署为服务；强大的社区采用；提供企业友好功能（认证、日志集成）。                                              |
| **SuperAGI**     | 框架（开源）             | Python                           | ~6k               | 自主 AI 代理平台；附带工具集成和记忆；管理代理的 Web UI；旨在实现长期任务自动化（受 AutoGPT 启发）。                                                                   |
| **Marvin**       | 库（开源，MIT）          | Python                           | ~3k（2025）       | 带输出 schema 的 AI 函数（Pydantic 验证）；确保 LLM 的结构化输出；与外部工具集成；专注于可靠和可测试的 AI 行为。                                                       |
| **Dify**         | 平台（开源，Apache-2.0） | Python（FastAPI）+ TS（Next.js） | 10 万+            | 全栈 LLMOps 平台；**可视化工作流画布**；多模型支持（OpenAI、本地等）；内置 RAG 管道（文档摄入到问答）；**代理**支持（50+工具）；监控与用户管理；可本地部署或云端部署。 |
| **Eino**         | 框架（开源，Apache-2.0） | Go                               | ~5k               | Go 中的强类型编排；链和图执行模型；适用于高性能服务；提供并发和流式支持；字节跳动内部使用（经大规模验证）。                                                            |
| **Promptulate**  | 库（开源）               | Python                           | <1k               | 轻量级代理框架（社区驱动）；更容易与中文 LLM（如文心一言）集成；提供简单的工具使用和本地部署自动化模式。                                                               |
| **百炼（阿里）** | 云平台（专有）           | （多种）                         | –                 | 阿里云上的企业开发套件；支持阿里通义模型；无代码提示词和工作流设计界面；与云服务和安全功能紧密集成。                                                                   |
| **百度千帆**     | 云平台（专有）           | （多种）                         | –                 | 百度一站式模型工作室；微调、提示词设计和部署工具；支持文心一言等；针对企业和政府 AI 采用，强调合规性。                                                                 |

（表格说明：“低代码平台”指具有 GUI 的应用构建工具。**星标数**为 2025 年近似值。专有云平台不依赖 GitHub 星标指标。RAG=检索增强生成。）

## 理解工作流结构

在 AI 代理语境中，**工作流结构**指代理为实现目标而遵循的有组织的步骤或模块序列。简单来说，它是代理运作的“行动计划”或蓝图。**代理工作流**通常由一系列相互关联的动作组成（如*计划 → 执行 → 观察 → 重复*），代理会循环执行这些动作，直到任务完成。代理工作流结构的关键要素通常包括：

-   **任务分解与规划**：代理将复杂目标分解为更小的子任务。它可能“思考”或使用 LLM 生成行动计划或动作序列。这有时是明确的步骤（使用规划器），有时隐含在代理的提示词策略中。
-   **工具使用动作**：代理根据需要调用外部工具或 API。每个动作通常包括 LLM 决定使用哪个工具及输入（如搜索查询、计算器、数据库访问等），然后执行该工具并接收结果。这些动作步骤是构成工作流的“结构化步骤”。
-   **观察与反思**：每次工具使用或中间步骤后，代理会观察结果并评估进度。工作流结构可能包含条件逻辑或循环——例如，代理检查目标是否达成或是否需要下一步。如果未完成，它会将新信息反馈到 LLM 中，用于下一个推理周期。
-   **终止/输出**：工作流定义了代理应生成最终答案（并停止调用工具）的条件或步骤。这可能是当代理的 LLM 决定输出答案而非动作时，或当达到预设的迭代次数时。结构中可能包含格式化步骤，用于呈现最终结果。

**工作流 vs 代理**：需要注意刚性*工作流*与更灵活*代理*的区别。**工作流**（按 Anthropic 的定义）是通过预定的固定步骤序列编排的 LLM 调用和工具使用系统（即 LLM 驱动的管道）。相比之下，**代理**具有更动态的结构——LLM 根据上下文决定采取哪些步骤及顺序，而非遵循硬编码路径。在实践中，许多真实世界的 AI 系统会混合两者：部分是**结构化工作流**（为可靠性），部分是**代理式**（为灵活性）。因此，代理工作流的结构指的是整体架构：确定性部分（如有）和代理式（动态）部分如何组织成操作序列。

总之，代理工作流的结构是代理为达成解决方案而迭代执行的*一系列结构化步骤和决策*。它可以简单到固定的提示词链（用于定义明确的任务），也可以复杂到循环（代理规划、使用工具、重新规划，直到满足终止条件）。设计良好的工作流结构清晰定义了代理从一个步骤过渡到下一个步骤的方式，确保流程连贯且可检查或控制。

## 清晰的指令与输出格式化

无论使用哪种框架，LLM 应用的基本最佳实践是设计**具有明确指令的清晰提示词**，尤其要明确期望的输出格式。默认情况下，LLM 输出自由文本，这在下游使用中可能不可预测，因此开发者通常需要引导模型生成结构化输出。本节介绍确保 LLM 输出格式规范且符合要求的技术和工具。

**1. 提示词清晰度**：始终在提示词中指定期望的*输出格式*。例如，若需要 JSON 输出，提示词可能说：“以 JSON 对象形式提供答案，包含键`X`、`Y`、`Z`。” 若用户期望项目符号列表，提示词应提及“以项目符号列表形式回答”。许多框架提供便捷的提示词模板实现此功能。例如，LangChain 等框架允许定义输出解析器或 schema，并会自动附加类似“你应仅回复有效的 JSON”的指令。明确的指令能显著提高模型输出格式正确的概率。使用少样本示例可进一步强化格式（例如，展示样本输入和格式完美的输出）。

**2. 结构化输出解析器**：多个库可帮助验证并强制 LLM 输出符合预期结构：

-   **Guardrails AI（Python）**：Guardrails 允许开发者在特殊的基于 XML 的.rail 文件中定义输出 schema 和验证规则，并包装 LLM 调用以强制执行这些规则。其底层会检查 LLM 的响应是否符合 schema（例如，包含特定字段的有效 JSON，或不含禁用内容的文本），若不符合，可自动触发重试或修正提示词。Guardrails 本质上在 LLM 之上提供了一层保障——使用类似 Pydantic 的类型检查甚至语义检查。这样，你可以保证最终输出*始终*符合格式（或系统会持续请求直到符合或终止）。它尤其适用于强制结构化输出（JSON、SQL 查询等）和注入安全过滤器。NVIDIA 的 NeMo Guardrails 是类似概念，面向企业部署。
-   **Zod + TypeChat（TypeScript）**：在 Node.js/TypeScript 生态中，常用方法是使用 Zod 库定义 LLM 输出的预期 schema，并结合技术验证模型响应。**Zod**是流行的 TS 库，用于 schema 验证，可描述输出格式并在运行时验证数据。微软的实验性**TypeChat**库基于此构建：你为响应定义 TypeScript 接口或 Zod schema，TypeChat 会格式化包含这些类型定义的系统提示词（将其转换为可读形式），以便 LLM 遵循该结构。LLM 响应后，库会解析 JSON 并使用 Zod 检查类型——若验证失败，它可自动生成类似“修复输出以匹配 schema”的后续提示词并发送给模型。此循环会持续到输出有效或达到限制。通过利用 Zod schema，开发者获得了 AI 的明确契约，并能系统地处理错误。以下片段说明了这种模式：在 Zod 中定义`HorseSchema`，将其包含在提示词中（描述每个字段），然后用于将结果解析为类型化对象：

> “这是一个 Zod schema……你可以创建运行时 schema 来检查和验证类型。事实证明，你还可以描述字段，这在构建发送给 OpenAI API 的查询时很有用……请求……说：仅以 JSON 文档形式响应，并严格遵循以下 TypeScript schema……（获取响应后）若为字符串，我们执行`HorseSchema.parse(JSON.parse(responseContent))`。”

这种方法在代码中生成结构良好的 JSON 对象，若模型未遵守，则返回错误，你可随后处理（例如，再次请求或抛出异常）。TypeChat/Zod 的优势是与开发者定义类型的常规实践一致，将 LLM 输出纳入传统的类型检查工作流。

-   **Pydantic 及其他（Python）**：与 TS 的 Zod 类似，Python 开发者常使用**Pydantic**数据模型定义 LLM 响应的结构。例如，可创建包含`answer: str`和`source_urls: List[str]`字段的 Pydantic 类，然后提示 LLM 输出对应的 JSON。LLM 响应后，可执行`MyModel.parse_raw(llm_output)`获取 Python 对象或错误。LangChain 等库的`StructuredOutputParser`与 Pydantic 配合简化了此模式（自动生成包含 schema 的少样本提示词并执行解析）。如前所述，Marvin 通过允许从 AI 函数返回 Pydantic 对象来拥抱这种模式——它会在内部循环直到解析成功。这些工具的核心原则相同：通过形式化预期输出结构，我们既通过提示词引导 LLM，又通过编程方式验证结果。

**3. 模型特定功能**：较新的模型 API 提供原生结构化输出方式：

-   **OpenAI 函数调用与 JSON 模式**：OpenAI 的 API（适用于 GPT-3.5-Turbo 和 GPT-4）在 2023 年中期引入了*函数调用*，2024 年又推出了明确的“结构化输出”模式。通过函数调用，你定义带 JSON schema 参数的函数，若在提示词中设置`function_call`，模型可直接输出符合该 schema 的 JSON 对象（API 返回结构化 Python 字典，而非仅文本）。2024 年，OpenAI 为函数定义添加了`strict: true`选项，强制模型严格遵循提供的 JSON schema。这显著提高了可靠性——OpenAI 报告，带结构化输出（strict）的 GPT-4 对复杂 schema 的合规率达*100%*，而基于提示词的尝试合规率<40%。本质上，模型的解码器受到约束，只能生成符合 schema 的有效 JSON 令牌。这对于表单填写、代码生成或任何需要严格格式的场景都是变革性的，因为它无需多次验证重试。只要可用，建议使用此类原生功能，因为它们在模型层面强制正确性。例如，要获取包含名称和价格的项目列表，你可指定`submit_order(items: list[Item])`函数（其中`Item`包含`name`和`price`字段）；若`strict: true`，模型只会返回匹配确切类型的`{"items": [...]}`，或在无法生成时内部触发错误。
-   **其他提供商**：竞争 LLM 服务也提供类似功能——例如，Anthropic 的 Claude 采用“宪法 AI”方法，严格遵循格式化指令；一些开源库（如**Transformers**）允许应用**输出正则约束**或**logit 处理器**，使模型偏向特定格式（尽管这些是高级用法，通常需要自托管模型）。例如，你可使用匹配 JSON 的正则表达式，让生成器受该模式约束，尽管这对复杂输出可能非易事。

**4. 指令风格**：编写用于格式化的系统或用户提示词时，应尽可能直接和具体。最佳实践包括：

-   用**大写字母**或特殊令牌（部分使用`<json>`标签或 markdown）声明格式。例如，“仅输出 JSON，别无其他。”或“答案以`BEGINJSON`开头，以`ENDJSON`结尾。” 这些有助于模型避免无关文本。
-   若使用特定框架，利用其内置格式强制器。（例如，LangChain 的`OutputFixingParser`会尝试通过解析错误消息修复 JSON。如前所述，Guardrails 可自动修正或重新请求。）
-   在提示词中提供样本查询后的格式良好输出示例（少样本）。模型通常从示例中学习格式比从描述中更好。
-   若对话较长，提醒模型格式（你可让系统提示词始终包含“以 JSON 回答”的指令）。

总之，**清晰的指令和输出 schema**对于将 LLM 从创造性文本生成器转变为软件系统的可靠组件至关重要。现代框架和库正越来越多地整合这些技术，使开发者能**将 LLM 输出视为类型化函数返回或 API 响应**，这对于构建具有高正确性要求的复杂应用至关重要。通过结合强大的提示词实践与验证工具（如 Guardrails 或 Zod/TypeChat），并利用 OpenAI 结构化输出等功能，可最大限度减少“格式幻觉”问题，确保 AI 的响应能直接被后续程序使用。

## 代理执行过程中的内容安全策略

内容安全是部署 AI 代理的关键方面，尤其当代理自主运行并与各种输入交互时。**代理工作流必须纳入保障措施**，防止在任何步骤生成有害、敏感或违反政策的内容。制定内容安全策略涉及多个层面：

-   **系统级指南（政策提示词）**：通过系统指令设定基调，概述不可接受的内容。例如，给 LLM 的系统消息可能包含：“助手不得生成亵渎、仇恨言论或个人身份信息。” 提示词层面的明确政策有助于从一开始就对齐模型行为。许多 LLM（尤其是通过人类反馈强化学习微调的模型）若被正确指示遵循内容政策，会内置合规性。
-   **输入和输出过滤**：对用户输入和代理输出都实施过滤。**内容审核 API**或模型可扫描文本中的禁用内容。例如，可在代理处理前调用 OpenAI 的内容审核 API 或类似服务检查用户查询，在返回给用户前检查代理响应。若出现标记内容（如色情内容、暴力、政治敏感词等），系统可拒绝请求或净化输出。这作为安全网，捕捉模型内部保障可能遗漏的内容。
-   **工具使用保障**：当代理使用工具（如运行代码、网页搜索或 API）时，施加限制防止不安全操作。这可通过**沙箱化**某些操作和限制权限实现。例如，若代理有执行代码的工具，在无网络访问或文件写入权限的沙箱环境中运行，以避免危害。若代理可查询数据库，赋予其只读权限，防止修改数据。这些是“工具内保障”——设计工具时只允许安全操作。开发者还可在工具包装器中硬编码约束（例如，剥离 shell 工具中的任何禁用命令，或在网页搜索工具中屏蔽特定网站）。
-   **回调和干预点**：许多框架在代理循环的各个阶段支持**回调**或钩子。你可使用这些注入安全检查。例如，每次 LLM 响应（可能包含工具决策或消息）后，运行一个函数检查内容是否违反政策，或检查预期的工具使用是否被允许。若出现问题（如代理即将输出机密信息或使用禁用工具），回调可修改代理动作或终止工作流。这种设计允许动态干预：实时监控代理行为，而非仅在输入/输出边界。
-   **多阶段审核（辅助代理）**：更高级的策略是在工作流中使用次级**“审核”代理或模型**。例如，可让主代理生成草稿答案，然后由第二个代理（或分类器模型）审核该草稿的安全性，若违反指南则批准或指示主代理修改。这类似“人机协作”，但实现自动化。Anthropic 的“并行保障”模式指出，使用单独的模型实例筛选内容可能比让同一模型尝试在线自我审查更有效。
-   **持续更新与合规**：保持安全策略与最新政策和法规同步。这在不同司法管辖区尤为重要。例如，在美国和欧洲，隐私和公平性可能是关键问题，而在中国，法律对政治敏感内容、谣言等有更严格规定。中国 AI 平台通常有*预定义的关键词黑名单和合规检查*——例如，华为小艺平台指南禁止代理生成任何违法、宣扬非法活动或包含色情/低俗内容的内容。确保你的代理安全过滤器包含所需的地区特定规则。最终，**品牌和用户安全**考虑应决定代理绝对不允许说或做的事情，这些应编码在多层防御中（提示词指令、过滤工具、审核 I/O 等）。

强大的内容安全策略采用**冗余设计**：多个保障措施协同工作，捕捉不同的故障模式。例如，OpenAI 的代理参考架构结合了基于 LLM 的内容过滤器、基于规则的过滤器（如敏感数据的正则检查）和模型自身的拒绝机制，确保各环节合规。通过从一开始就规划安全性并使用上述工具，可显著降低代理失控的风险。请记住，代理可能影响现实世界（通过工具动作或影响用户），因此**安全不仅是避免不良文本**——还包括防止代理超出范围的动作。保障措施定义了代理自主性的*边界*，确保其在内容和行为上都处于可接受的范围内。

## 代理工作流的追踪与可观测性

**追踪**指记录和监控代理工作流的分步执行。鉴于 LLM 代理的复杂性和非确定性，清晰观测代理在每个阶段的行为至关重要。有效的追踪使开发者能调试问题、优化性能，并确保代理的推理与预期一致。

代理追踪的关键方面包括记录：

-   **提示词和模型响应**：每次代理调用 LLM（做决策或生成输出）时，应捕获确切的提示词和 LLM 的响应。这包括系统消息、用户输入和助手在每个回合的回复。通过检查这些，可理解代理*为何*采取特定动作或生成特定答案。
-   **工具调用**：每次工具使用（调用的工具及输入）和工具返回的结果都应记录。这对于了解工具是否被正确使用以及它向代理提供了哪些数据至关重要。
-   **中间状态/记忆**：若代理维护任何记忆或中间状态（如待办事项代理中的任务列表，或隐藏提示词中的思维链），追踪应捕捉此状态随时间的更新。
-   **最终输出和终止原因**：记录代理给出的最终答案，并注明代理停止的原因（是否达到停止条件、步骤用尽或遇到错误）。

现代代理框架通常内置追踪功能，或易于集成可观测性工具。例如，**LangChain 的 LangSmith**平台提供详细追踪，包含每个步骤的所有输入和输出，让开发者能全面了解代理行为。这意味着你可以检查追踪，查看导致最终答案的所有 LLM 调用、决策和工具动作序列。同样，OpenAI Agents SDK 自动**追踪代理运行**，并可通过 OpenTelemetry 兼容接口将这些追踪发送到外部监控服务（如 Logfire、AgentOps 等）。这些工具通常提供 Web 仪表板或日志，其中每个代理“运行”都被索引，你可以深入查看运行的每个步骤。

若不使用现成解决方案，在自己的代理中实现追踪时，可在代码的关键点插入日志语句。开发者在原型设计时，通常对每个步骤使用简单的控制台或文件日志。例如，LLM 返回消息后，打印该消息；调用工具时，打印工具名称和参数；工具返回后，打印结果。但随着时间推移，更结构化的方法更有利：使用可观测性 SDK 或数据库存储追踪，可实现跨多次运行的搜索和聚合。这有助于识别常见故障模式。追踪对于**性能监控**也非常宝贵——你可以记录每个步骤的耗时或使用的令牌，并用这些优化工作流（如某个工具调用太慢或提示词太长）。

总之，**追踪提供了信任和优化代理系统所需的透明度**。有了完整的追踪日志，你可以回答诸如：代理为何采取该动作？错误答案在哪里出现？它使用了多少步骤？有了这些见解，你可以迭代改进代理的提示词或逻辑。人们常说，对于 LLM 应用，_可观测性是关键_，因为传统单元测试可能无法捕捉不可预测的行为——但追踪会展示每个实例中的确切情况。因此，将追踪（及追踪审查）作为代理开发周期的常规部分。
