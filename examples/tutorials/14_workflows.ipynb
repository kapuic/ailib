{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“ Prerequisites\n",
    "\n",
    "This notebook requires an OpenAI API key to run the workflows.\n",
    "\n",
    "To set your API key:\n",
    "\n",
    "```python\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = 'your-api-key-here'\n",
    "```\n",
    "\n",
    "All examples in this notebook are **fully executable** and will show real LLM-generated results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. Workflows - Orchestrating Complex AI Tasks\n",
    "\n",
    "This tutorial introduces AILib's workflow system, which extends beyond simple chains to provide powerful orchestration capabilities while maintaining simplicity.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- Creating basic workflows\n",
    "- Adding conditional logic\n",
    "- Using loops and iteration\n",
    "- Parallel execution\n",
    "- State management\n",
    "- Error handling and retries\n",
    "- Human-in-the-loop workflows\n",
    "- Composing complex workflows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… API key found! Ready to run workflows.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from ailib import create_workflow\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "# For async execution in Jupyter\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Check for API key\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"âŒ Error: OPENAI_API_KEY environment variable is required\")\n",
    "    print(\"\\nTo set it in this notebook, run:\")\n",
    "    print(\"os.environ['OPENAI_API_KEY'] = 'your-api-key-here'\")\n",
    "    raise ValueError(\"Please set your OpenAI API key to continue\")\n",
    "\n",
    "print(\"âœ… API key found! Ready to run workflows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary modules and set up our environment:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated haiku:\n",
      "Artificial mind,\n",
      "Learning and evolving fast,\n",
      "Future unknown path.\n",
      "\n",
      "âœ“ Created and ran a simple workflow with 1 step\n"
     ]
    }
   ],
   "source": [
    "# The simplest workflow - one line!\n",
    "simple_workflow = create_workflow(\"Write a haiku about AI\")\n",
    "\n",
    "# Run the workflow\n",
    "result = await simple_workflow.run()\n",
    "print(\"Generated haiku:\")\n",
    "print(result)\n",
    "\n",
    "print(f\"\\nâœ“ Created and ran a simple workflow with {len(simple_workflow.steps)} step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Workflows\n",
    "\n",
    "Let's start with the simplest possible workflow:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created workflow with 3 steps\n",
      "\n",
      "Workflow result:\n",
      "1. å„ªã—ã„é›«ãŒè½ã¡ã‚‹ (Yasashii shizuku ga ochiru) - Gentle drops fall\n",
      "2. åœ°çƒã®çœ ã‚Šã‚’è¦šã¾ã™ (Chikyuu no nemuri wo samasu) - Waking the earth from its slumber\n",
      "3. æ˜¥ã®ç”˜ã„ã‚»ãƒ¬ãƒŠãƒ¼ãƒ‡ (Haru no amai serenade) - Sweet serenade of spring\n",
      "\n",
      "==================================================\n",
      "\n",
      "Named steps workflow result:\n",
      "1. Crisp leaves fall to the ground - This line describes the action of leaves falling from trees during autumn. The word \"crisp\" suggests that the leaves are dry and brittle, characteristic of the fall season.\n",
      "\n",
      "2. Colors of red, gold, and brown - This line refers to the variety of colors that leaves turn during autumn. The colors red, gold, and brown are commonly associated with fall foliage and add to the beauty of the season.\n",
      "\n",
      "3. Nature's tapestry - This line conveys the idea that the changing colors of the leaves create a beautiful and intricate pattern, much like a tapestry. It suggests that nature's beauty and artistry can be seen in the changing of the seasons.\n"
     ]
    }
   ],
   "source": [
    "# Multi-step workflow - with proper context passing\n",
    "multi_step = create_workflow(\n",
    "    [\n",
    "        \"Write a haiku about {topic}\",\n",
    "        \"Translate this to Japanese: {previous}\",\n",
    "        \"Explain the meaning of each line from the original haiku: {previous_result}\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"Created workflow with {len(multi_step.steps)} steps\")\n",
    "\n",
    "# Run with parameters\n",
    "result = await multi_step.run(topic=\"spring rain\")\n",
    "print(\"\\nWorkflow result:\")\n",
    "print(result)\n",
    "\n",
    "# Alternative: Use named steps for more explicit control\n",
    "print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "\n",
    "multi_step_named = (\n",
    "    create_workflow()\n",
    "    .step(\"Write a haiku about {topic}\", name=\"haiku\")\n",
    "    .step(\"Translate to Japanese: {haiku}\", name=\"translation\")\n",
    "    .step(\"Explain the meaning of each line from: {haiku}\", name=\"explanation\")\n",
    ")\n",
    "\n",
    "result_named = await multi_step_named.run(topic=\"autumn leaves\")\n",
    "print(\"Named steps workflow result:\")\n",
    "print(result_named)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Conditional Logic\n",
    "\n",
    "Add decision-making to your workflows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallel search workflow created\n",
      "\n",
      "Completed in 5.92 seconds (parallel execution is faster!)\n",
      "\n",
      "Synthesized results:\n",
      "Overall, the research conducted on the effects of social media on mental health has shown a complex relationship between the two. While excessive use of social media has been linked to negative mental health outcomes such as depression, anxiety, and feelings of loneliness, there are also positive aspects to consider. Social media can provide a sense of connection and support, and can be a valuable tool for self-expression and communication. It is important for individuals to be mindful of their social media use and to prioritize real-life interactions and self-care practices to maintain a healthy balance.\n"
     ]
    }
   ],
   "source": [
    "# Parallel search across multiple sources\n",
    "search_workflow = (\n",
    "    create_workflow()\n",
    "    .parallel(\n",
    "        \"Write 3 facts about quantum computing\",\n",
    "        \"List 3 recent breakthroughs in quantum computing\",\n",
    "        \"Name 3 challenges facing quantum computing\",\n",
    "    )\n",
    "    .all()  # Wait for all results\n",
    "    .step(\"Synthesize all findings into a brief summary\")\n",
    ")\n",
    "\n",
    "print(\"Parallel search workflow created\")\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "results = await search_workflow.run()\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"\\nCompleted in {elapsed:.2f} seconds (parallel execution is faster!)\")\n",
    "print(\"\\nSynthesized results:\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processing workflow created\n",
      "\n",
      "Descriptions generated:\n",
      "\n",
      "1. 1. Python is a versatile programming language known for its simplicity and readability, making it ideal for tasks such as web development, data analysis, and artificial intelligence.\n",
      "\n",
      "2. Java is a widely-used programming language known for its platform independence, making it a popular choice for developing desktop, web, and mobile applications.\n",
      "\n",
      "3. JavaScript is a scripting language primarily used for adding interactivity to web pages, allowing developers to create dynamic and interactive user experiences on websites.\n"
     ]
    }
   ],
   "source": [
    "# For-each loop\n",
    "batch_workflow = (\n",
    "    create_workflow()\n",
    "    .step(\"List 3 popular programming languages\")\n",
    "    .for_each(\"language\")\n",
    "    .do(\"Write a 2-sentence description of {language} highlighting its main use case\")\n",
    ")\n",
    "\n",
    "print(\"Batch processing workflow created\")\n",
    "\n",
    "result = await batch_workflow.run()\n",
    "print(\"\\nDescriptions generated:\")\n",
    "for i, desc in enumerate(result, 1):\n",
    "    print(f\"\\n{i}. {desc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loops and Iteration\n",
    "\n",
    "Process lists of items or repeat operations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Race workflow created - will return fastest result\n",
      "\n",
      "Completed in 5.97 seconds\n",
      "Winner: Quick\n"
     ]
    }
   ],
   "source": [
    "# Race condition - first to complete wins\n",
    "# Let's create tasks with different complexity levels\n",
    "import time\n",
    "\n",
    "fast_response = (\n",
    "    create_workflow()\n",
    "    .parallel(\n",
    "        \"Say 'quick'\", \"Write a detailed 500-word essay about the history of computing\"\n",
    "    )\n",
    "    .race()  # Return whichever completes first\n",
    ")\n",
    "\n",
    "print(\"Race workflow created - will return fastest result\")\n",
    "\n",
    "start = time.time()\n",
    "result = await fast_response.run()\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"\\nCompleted in {elapsed:.2f} seconds\")\n",
    "print(f\"Winner: {result[:50]}...\" if len(result) > 50 else f\"Winner: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Parallel Execution\n",
    "\n",
    "Run multiple operations concurrently for better performance:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallel search workflow created\n",
      "\n",
      "Completed in 5.95 seconds (parallel execution is faster!)\n",
      "\n",
      "Synthesized results:\n",
      "The research indicates that there is a growing concern about the impact of social media on mental health, particularly among young people. Excessive use of social media has been linked to feelings of loneliness, depression, anxiety, and low self-esteem. Additionally, the comparison culture and unrealistic standards portrayed on social media can contribute to negative body image issues. It is important for individuals to be mindful of their social media usage and seek support if they are experiencing negative effects on their mental health.\n"
     ]
    }
   ],
   "source": [
    "# Parallel search across multiple sources\n",
    "search_workflow = (\n",
    "    create_workflow()\n",
    "    .parallel(\n",
    "        \"Write 3 facts about quantum computing\",\n",
    "        \"List 3 recent breakthroughs in quantum computing\",\n",
    "        \"Name 3 challenges facing quantum computing\",\n",
    "    )\n",
    "    .all()  # Wait for all results\n",
    "    .step(\"Synthesize all findings into a brief summary\")\n",
    ")\n",
    "\n",
    "print(\"Parallel search workflow created\")\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "results = await search_workflow.run()\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"\\nCompleted in {elapsed:.2f} seconds (parallel execution is faster!)\")\n",
    "print(\"\\nSynthesized results:\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created workflow with automatic retry on API calls\n"
     ]
    }
   ],
   "source": [
    "# Automatic retry on failure\n",
    "resilient_workflow = (\n",
    "    create_workflow()\n",
    "    .step(\n",
    "        \"Call external API to get data for: {query}\",\n",
    "        retry=3,  # Retry up to 3 times\n",
    "        timeout=5.0,  # 5 second timeout\n",
    "    )\n",
    "    .step(\"Process the API response\")\n",
    "    .step(\"Store results in database\")\n",
    ")\n",
    "\n",
    "print(\"Created workflow with automatic retry on API calls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created workflow with comprehensive error handling\n"
     ]
    }
   ],
   "source": [
    "# Custom error handling\n",
    "error_handling_workflow = (\n",
    "    create_workflow()\n",
    "    .step(\"Perform risky operation\")\n",
    "    .on_error()\n",
    "    .retry(max_attempts=2, backoff_factor=2.0)\n",
    "    .do(\"Log error details\", \"Send alert to admin\")\n",
    "    .finally_do(\"Clean up resources\")\n",
    ")\n",
    "\n",
    "print(\"Created workflow with comprehensive error handling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created workflow with schema validation\n"
     ]
    }
   ],
   "source": [
    "# Define expected output structure\n",
    "class ProductAnalysis(BaseModel):\n",
    "    name: str\n",
    "    category: str\n",
    "    price_range: str\n",
    "    key_features: List[str]\n",
    "    target_audience: str\n",
    "    sentiment_score: float\n",
    "\n",
    "\n",
    "# Workflow with validated outputs\n",
    "analysis_workflow = (\n",
    "    create_workflow()\n",
    "    .step(\n",
    "        \"Analyze this product description: {description}\",\n",
    "        output_schema=ProductAnalysis,  # Ensures valid structure\n",
    "        retry=2,  # Retry if validation fails\n",
    "    )\n",
    "    .step(\"Generate marketing tagline based on analysis\")\n",
    ")\n",
    "\n",
    "print(\"Created workflow with schema validation\")\n",
    "# result = await analysis_workflow.run(description=\"...\")\n",
    "# result is guaranteed to be a valid ProductAnalysis object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. State Management\n",
    "\n",
    "Maintain context and data throughout workflow execution:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stateful aggregation workflow created\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'items_processed'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m      2\u001b[39m stateful_workflow = (\n\u001b[32m      3\u001b[39m     create_workflow()\n\u001b[32m      4\u001b[39m     .with_state({\u001b[33m\"\u001b[39m\u001b[33mtotal_cost\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m0\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mitems_processed\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m0\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33merrors\u001b[39m\u001b[33m\"\u001b[39m: []})\n\u001b[32m   (...)\u001b[39m\u001b[32m     21\u001b[39m     )\n\u001b[32m     22\u001b[39m )\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStateful aggregation workflow created\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m stateful_workflow.run()\n\u001b[32m     26\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mResult: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/asyncio/futures.py:287\u001b[39m, in \u001b[36mFuture.__await__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done():\n\u001b[32m    286\u001b[39m     \u001b[38;5;28mself\u001b[39m._asyncio_future_blocking = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m  \u001b[38;5;66;03m# This tells Task to wait for completion.\u001b[39;00m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done():\n\u001b[32m    289\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mawait wasn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt used with future\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/asyncio/tasks.py:349\u001b[39m, in \u001b[36mTask.__wakeup\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[32m    348\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m349\u001b[39m         \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    350\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    351\u001b[39m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[32m    352\u001b[39m         \u001b[38;5;28mself\u001b[39m.__step(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/asyncio/futures.py:203\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/asyncio/tasks.py:277\u001b[39m, in \u001b[36mTask.__step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    275\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    276\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m         result = coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    279\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Coding/ailib/src/ailib/workflows/_core.py:305\u001b[39m, in \u001b[36mWorkflow.run\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    292\u001b[39m     trace.add_step(\n\u001b[32m    293\u001b[39m         TraceStep(\n\u001b[32m    294\u001b[39m             name=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mstep_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext.step_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_start\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    301\u001b[39m         )\n\u001b[32m    302\u001b[39m     )\n\u001b[32m    304\u001b[39m \u001b[38;5;66;03m# Execute step\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m305\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m step.execute(context)\n\u001b[32m    307\u001b[39m \u001b[38;5;66;03m# Update context\u001b[39;00m\n\u001b[32m    308\u001b[39m context.set_result(step.name, result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Coding/ailib/src/ailib/workflows/_core.py:109\u001b[39m, in \u001b[36mSimpleStep.execute\u001b[39m\u001b[34m(self, context)\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Execute the step.\"\"\"\u001b[39;00m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.prompt_or_func, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    108\u001b[39m     \u001b[38;5;66;03m# LLM-based step\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._execute_llm(context)\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    111\u001b[39m     \u001b[38;5;66;03m# Function-based step\u001b[39;00m\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._execute_function(context)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Coding/ailib/src/ailib/workflows/_core.py:124\u001b[39m, in \u001b[36mSimpleStep._execute_llm\u001b[39m\u001b[34m(self, context)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;66;03m# Format the prompt with context\u001b[39;00m\n\u001b[32m    117\u001b[39m \u001b[38;5;66;03m# Include previous_result for easy reference in prompts\u001b[39;00m\n\u001b[32m    118\u001b[39m format_vars = {\n\u001b[32m    119\u001b[39m     **context.variables,\n\u001b[32m    120\u001b[39m     **context.results,\n\u001b[32m    121\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mprevious_result\u001b[39m\u001b[33m\"\u001b[39m: context.current_result,\n\u001b[32m    122\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mprevious\u001b[39m\u001b[33m\"\u001b[39m: context.current_result,  \u001b[38;5;66;03m# Shorter alias\u001b[39;00m\n\u001b[32m    123\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m prompt = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprompt_or_func\u001b[49m\u001b[43m.\u001b[49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mformat_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# Get LLM client\u001b[39;00m\n\u001b[32m    127\u001b[39m client = context.llm_client \u001b[38;5;129;01mor\u001b[39;00m create_client(\u001b[33m\"\u001b[39m\u001b[33mgpt-3.5-turbo\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: 'items_processed'"
     ]
    }
   ],
   "source": [
    "# Workflow with persistent state\n",
    "stateful_workflow = (\n",
    "    create_workflow()\n",
    "    .with_state({\"total_cost\": 0, \"items_processed\": 0, \"errors\": []})\n",
    "    .step(\"List 3 items to process\")\n",
    "    .for_each(\"item\")\n",
    "    .do(\n",
    "        create_workflow()\n",
    "        .step(\"Calculate cost for {item} (return a number between 10 and 100)\")\n",
    "        .step(\n",
    "            lambda ctx: {\n",
    "                # Parse the cost from the response and update state\n",
    "                \"total_cost\": ctx.state[\"total_cost\"] + 50,  # Simplified for demo\n",
    "                \"items_processed\": ctx.state[\"items_processed\"] + 1,\n",
    "            }\n",
    "        )\n",
    "        .build()  # IMPORTANT: Build the sub-workflow\n",
    "    )\n",
    "    .step(\n",
    "        \"Generate report: Processed {items_processed} items with total cost ${total_cost}\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Stateful aggregation workflow created\")\n",
    "result = await stateful_workflow.run()\n",
    "print(f\"\\nResult: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created workflow with automatic retry\n",
      "Result: Sum of numbers: 250\n",
      "\n",
      "==================================================\n",
      "\n",
      "Created workflow with error handling\n",
      "Result: Once the workflow is established, it is important to monitor and evaluate its effectiveness regularly. This can be done by collecting feedback from team members, analyzing key performance indicators, and making necessary adjustments to improve efficiency and productivity.\n",
      "\n",
      "Additionally, communication is key in any workflow. Make sure to keep all team members informed about any changes or updates to the workflow, and encourage open communication to address any issues or concerns that may arise.\n",
      "\n",
      "Lastly, don't be afraid to experiment with different tools or strategies to optimize the workflow. Continuous improvement is essential for ensuring that the workflow remains effective and efficient over time.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Created workflow with strict validation (may retry if format is wrong)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jc/w0z7zygn0nx8x5dw98tm2k1w0000gn/T/ipykernel_95335/64480649.py:59: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  @validator(\"items\")\n",
      "/var/folders/jc/w0z7zygn0nx8x5dw98tm2k1w0000gn/T/ipykernel_95335/64480649.py:65: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  @validator(\"total\")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Output validation failed - expected StrictFormat, got: I have 3 apples....",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Coding/ailib/src/ailib/workflows/_core.py:180\u001b[39m, in \u001b[36mSimpleStep._validate_output\u001b[39m\u001b[34m(self, output)\u001b[39m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    179\u001b[39m     \u001b[38;5;66;03m# First try direct JSON parsing\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     data = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output_schema(**data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/json/__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/json/decoder.py:337\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03mcontaining a JSON document).\u001b[39;00m\n\u001b[32m    335\u001b[39m \n\u001b[32m    336\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m end = _w(s, end).end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/json/decoder.py:355\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 83\u001b[39m\n\u001b[32m     72\u001b[39m validation_retry_workflow = (\n\u001b[32m     73\u001b[39m     create_workflow()\n\u001b[32m     74\u001b[39m     .step(\n\u001b[32m   (...)\u001b[39m\u001b[32m     79\u001b[39m     .step(\u001b[33m\"\u001b[39m\u001b[33mFormat the items as a numbered list\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     80\u001b[39m )\n\u001b[32m     82\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCreated workflow with strict validation (may retry if format is wrong)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m validation_retry_workflow.run()\n\u001b[32m     84\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mResult after validation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/asyncio/futures.py:287\u001b[39m, in \u001b[36mFuture.__await__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done():\n\u001b[32m    286\u001b[39m     \u001b[38;5;28mself\u001b[39m._asyncio_future_blocking = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m  \u001b[38;5;66;03m# This tells Task to wait for completion.\u001b[39;00m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done():\n\u001b[32m    289\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mawait wasn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt used with future\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/asyncio/tasks.py:349\u001b[39m, in \u001b[36mTask.__wakeup\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[32m    348\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m349\u001b[39m         \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    350\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    351\u001b[39m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[32m    352\u001b[39m         \u001b[38;5;28mself\u001b[39m.__step(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/asyncio/futures.py:203\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/asyncio/tasks.py:277\u001b[39m, in \u001b[36mTask.__step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    275\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    276\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m         result = coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    279\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Coding/ailib/src/ailib/workflows/_core.py:289\u001b[39m, in \u001b[36mWorkflow.run\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    280\u001b[39m     trace.add_step(\n\u001b[32m    281\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mstep_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext.step_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_start\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    282\u001b[39m         {\n\u001b[32m   (...)\u001b[39m\u001b[32m    285\u001b[39m         },\n\u001b[32m    286\u001b[39m     )\n\u001b[32m    288\u001b[39m \u001b[38;5;66;03m# Execute step\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m step.execute(context)\n\u001b[32m    291\u001b[39m \u001b[38;5;66;03m# Update context\u001b[39;00m\n\u001b[32m    292\u001b[39m context.set_result(step.name, result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Coding/ailib/src/ailib/workflows/_core.py:108\u001b[39m, in \u001b[36mSimpleStep.execute\u001b[39m\u001b[34m(self, context)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Execute the step.\"\"\"\u001b[39;00m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.prompt_or_func, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    107\u001b[39m     \u001b[38;5;66;03m# LLM-based step\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._execute_llm(context)\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    110\u001b[39m     \u001b[38;5;66;03m# Function-based step\u001b[39;00m\n\u001b[32m    111\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._execute_function(context)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Coding/ailib/src/ailib/workflows/_core.py:145\u001b[39m, in \u001b[36mSimpleStep._execute_llm\u001b[39m\u001b[34m(self, context)\u001b[39m\n\u001b[32m    143\u001b[39m     \u001b[38;5;66;03m# Validate output if schema provided\u001b[39;00m\n\u001b[32m    144\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output_schema:\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Coding/ailib/src/ailib/workflows/_core.py:198\u001b[39m, in \u001b[36mSimpleStep._validate_output\u001b[39m\u001b[34m(self, output)\u001b[39m\n\u001b[32m    195\u001b[39m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    197\u001b[39m     \u001b[38;5;66;03m# If validation fails, will be caught by retry logic\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    199\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOutput validation failed - expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.output_schema.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput[:\u001b[32m200\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    200\u001b[39m     )\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSchema validation failed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Output validation failed - expected StrictFormat, got: I have 3 apples...."
     ]
    }
   ],
   "source": [
    "# Import json for error handling demo\n",
    "import json\n",
    "from pydantic import validator\n",
    "\n",
    "# Example 1: Demonstrating retry with a task that might fail\n",
    "# We'll ask for a very specific format that might not work on first try\n",
    "retry_workflow = (\n",
    "    create_workflow()\n",
    "    .step(\n",
    "        \"Generate EXACTLY 5 random numbers between 1 and 100, formatted as a Python list like [1, 2, 3, 4, 5]\",\n",
    "        retry=3,  # Will retry up to 3 times if parsing fails\n",
    "    )\n",
    "    .step(lambda ctx: f\"Sum of numbers: {sum(eval(ctx.current_result))}\")\n",
    ")\n",
    "\n",
    "print(\"Created workflow with automatic retry\")\n",
    "result = await retry_workflow.run()\n",
    "print(f\"Result: {result}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "\n",
    "# Example 2: Demonstrating error handling with intentional failure\n",
    "# We'll create a workflow that tries to parse JSON and handles errors\n",
    "error_demo_workflow = (\n",
    "    create_workflow()\n",
    "    .step(\"Generate a product name\")\n",
    "    .step(  # This step intentionally tries something that might fail\n",
    "        lambda ctx: {\n",
    "            \"parsed\": json.loads(\n",
    "                ctx.current_result\n",
    "            ),  # This will fail since result isn't JSON\n",
    "            \"status\": \"success\",\n",
    "        }\n",
    "    )\n",
    "    .on_error()\n",
    "    .do(\n",
    "        \"Log: Previous step failed to parse JSON\",\n",
    "        \"Fallback: Use the raw product name instead\",\n",
    "    )\n",
    "    .finally_do(\"Continue with workflow\")\n",
    ")\n",
    "\n",
    "print(\"Created workflow with error handling\")\n",
    "try:\n",
    "    result = await error_demo_workflow.run()\n",
    "    print(f\"Result: {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"Workflow handled the error and continued!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "\n",
    "\n",
    "# Example 3: Schema validation with retry\n",
    "# This demonstrates how validation errors trigger retries\n",
    "class StrictFormat(BaseModel):\n",
    "    items: List[str]  # Must be exactly 3 items\n",
    "    total: int  # Must be the count of items\n",
    "\n",
    "    @validator(\"items\")\n",
    "    def validate_items_count(cls, v):\n",
    "        if len(v) != 3:\n",
    "            raise ValueError(\"Must have exactly 3 items\")\n",
    "        return v\n",
    "\n",
    "    @validator(\"total\")\n",
    "    def validate_total(cls, v, values):\n",
    "        if \"items\" in values and v != len(values[\"items\"]):\n",
    "            raise ValueError(\"Total must match item count\")\n",
    "        return v\n",
    "\n",
    "\n",
    "validation_retry_workflow = (\n",
    "    create_workflow()\n",
    "    .step(\n",
    "        \"Generate a response with exactly 3 items and their count\",\n",
    "        output_schema=StrictFormat,\n",
    "        retry=2,  # Will retry if validation fails\n",
    "    )\n",
    "    .step(\"Format the items as a numbered list\")\n",
    ")\n",
    "\n",
    "print(\"Created workflow with strict validation (may retry if format is wrong)\")\n",
    "result = await validation_retry_workflow.run()\n",
    "print(f\"Result after validation: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing error handling with simulated API failure:\n",
      "Result with error handling: Here are some steps to clean up an API connection:\n",
      "\n",
      "1. Check for any unused or redundant connections: Review all the API connections in your system and identify any connections that are no longer in use or are redundant. Remove these connections to declutter your system.\n",
      "\n",
      "2. Update outdated connections: Check if any API connections are using outdated endpoints or authentication methods. Update these connections to ensure they are using the latest standards and protocols.\n",
      "\n",
      "3. Consolidate similar connections: If you have multiple API connections that serve a similar purpose, consider consolidating them into a single connection. This can help simplify your system and reduce maintenance overhead.\n",
      "\n",
      "4. Secure connections: Ensure that all API connections are secure by using appropriate authentication mechanisms, encryption, and other security measures. This will help protect your data and prevent unauthorized access.\n",
      "\n",
      "5. Document connections: Document all API connections in your system, including their purpose, endpoints, authentication methods, and any other relevant information. This documentation will help you understand and manage your connections effectively.\n",
      "\n",
      "6. Monitor connections: Set up monitoring tools to track the performance and usage of your API connections. This will help you identify any issues or bottlenecks and take proactive measures to address them.\n",
      "\n",
      "7. Regularly review and update connections: Regularly review your API connections to ensure they are up-to-date and functioning properly. Update connections as needed to keep them optimized and secure.\n",
      "\n",
      "By following these steps, you can clean up your API connections and ensure that your system is running smoothly and securely.\n",
      "\n",
      "Testing same workflow without error:\n",
      "Result without error: There are several ways to clean up an API connection:\n",
      "\n",
      "1. Close the connection: Make sure to close the connection after you have finished using it. This will release any resources that were being used by the connection.\n",
      "\n",
      "2. Error handling: Implement proper error handling in your code to catch any exceptions that may occur during the connection process. This will help prevent any potential issues with the connection.\n",
      "\n",
      "3. Use connection pooling: If you are making multiple API calls, consider using connection pooling to reuse connections and minimize the overhead of creating new connections each time.\n",
      "\n",
      "4. Secure the connection: Ensure that the API connection is secure by using HTTPS and implementing authentication and authorization mechanisms to protect sensitive data.\n",
      "\n",
      "5. Monitor and optimize: Monitor the performance of your API connection and optimize it as needed to ensure efficient data transfer and minimize latency.\n",
      "\n",
      "By following these steps, you can ensure that your API connection is clean, secure, and efficient.\n"
     ]
    }
   ],
   "source": [
    "# More realistic error handling example\n",
    "# This workflow demonstrates handling API-like errors\n",
    "api_workflow = (\n",
    "    create_workflow()\n",
    "    .step(  # Simulate an API call that might fail\n",
    "        lambda ctx: (\n",
    "            {\"success\": False, \"error\": \"API rate limit exceeded\"}  # Simulate failure\n",
    "            if \"simulate_error\" in ctx.variables\n",
    "            else {\"success\": True, \"data\": \"API response data\"}\n",
    "        )\n",
    "    )\n",
    "    .step(  # This step checks the response and might raise an error\n",
    "        lambda ctx: (\n",
    "            ctx.current_result[\"data\"]\n",
    "            if ctx.current_result[\"success\"]\n",
    "            else (_ for _ in ()).throw(Exception(ctx.current_result[\"error\"]))\n",
    "        )\n",
    "    )\n",
    "    .on_error()\n",
    "    .retry(max_attempts=2, backoff_factor=2.0)\n",
    "    .do(\"Log error: API call failed\", \"Use cached data as fallback\")\n",
    "    .finally_do(\"Clean up API connection\")\n",
    ")\n",
    "\n",
    "print(\"Testing error handling with simulated API failure:\")\n",
    "try:\n",
    "    # This will trigger the error path\n",
    "    result = await api_workflow.run(simulate_error=True)\n",
    "    print(f\"Result with error handling: {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"Even with retries, the workflow failed: {e}\")\n",
    "\n",
    "print(\"\\nTesting same workflow without error:\")\n",
    "result = await api_workflow.run()  # No simulate_error flag\n",
    "print(f\"Result without error: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created workflow with human approval gate\n"
     ]
    }
   ],
   "source": [
    "# Workflow requiring approval\n",
    "content_workflow = (\n",
    "    create_workflow()\n",
    "    .step(\"Generate blog post about: {topic}\")\n",
    "    .step(\"Create social media snippets\")\n",
    "    .step(\"Design email newsletter\")\n",
    "    .require_approval(\n",
    "        notify=[\"content-team@company.com\"],\n",
    "        timeout=\"4 hours\",\n",
    "        message=\"Please review generated content before publishing\",\n",
    "    )\n",
    "    .step(\"Publish approved content to all channels\")\n",
    ")\n",
    "\n",
    "print(\"Created workflow with human approval gate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Workflow Composition\n",
    "\n",
    "Build complex workflows by combining simpler ones:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created workflow with schema validation\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Output validation failed - expected ProductAnalysis, got: This product description highlights the key features of the EcoFlow Portable Power Station, positioning it as a convenient and essential item for outdoor activities such as camping. The mention of its...",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Coding/ailib/src/ailib/workflows/_core.py:180\u001b[39m, in \u001b[36mSimpleStep._validate_output\u001b[39m\u001b[34m(self, output)\u001b[39m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    179\u001b[39m     \u001b[38;5;66;03m# First try direct JSON parsing\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     data = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output_schema(**data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/json/__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/json/decoder.py:337\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03mcontaining a JSON document).\u001b[39;00m\n\u001b[32m    335\u001b[39m \n\u001b[32m    336\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m end = _w(s, end).end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/json/decoder.py:355\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Run with a real product description\u001b[39;00m\n\u001b[32m     25\u001b[39m description = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[33mThe EcoFlow Portable Power Station is a compact, lightweight battery pack\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[33mperfect for camping and outdoor adventures. Features 500Wh capacity,\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[33msolar charging capability, and multiple USB/AC outlets. Priced at $399.\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m analysis_workflow.run(description=description)\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mGenerated tagline: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m     34\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mNote: The first step\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms output was automatically validated as a ProductAnalysis object!\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     35\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/asyncio/futures.py:287\u001b[39m, in \u001b[36mFuture.__await__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done():\n\u001b[32m    286\u001b[39m     \u001b[38;5;28mself\u001b[39m._asyncio_future_blocking = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m  \u001b[38;5;66;03m# This tells Task to wait for completion.\u001b[39;00m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done():\n\u001b[32m    289\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mawait wasn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt used with future\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/asyncio/tasks.py:349\u001b[39m, in \u001b[36mTask.__wakeup\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[32m    348\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m349\u001b[39m         \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    350\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    351\u001b[39m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[32m    352\u001b[39m         \u001b[38;5;28mself\u001b[39m.__step(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/asyncio/futures.py:203\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/asyncio/tasks.py:277\u001b[39m, in \u001b[36mTask.__step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    275\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    276\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m         result = coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    279\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Coding/ailib/src/ailib/workflows/_core.py:289\u001b[39m, in \u001b[36mWorkflow.run\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    280\u001b[39m     trace.add_step(\n\u001b[32m    281\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mstep_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext.step_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_start\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    282\u001b[39m         {\n\u001b[32m   (...)\u001b[39m\u001b[32m    285\u001b[39m         },\n\u001b[32m    286\u001b[39m     )\n\u001b[32m    288\u001b[39m \u001b[38;5;66;03m# Execute step\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m step.execute(context)\n\u001b[32m    291\u001b[39m \u001b[38;5;66;03m# Update context\u001b[39;00m\n\u001b[32m    292\u001b[39m context.set_result(step.name, result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Coding/ailib/src/ailib/workflows/_core.py:108\u001b[39m, in \u001b[36mSimpleStep.execute\u001b[39m\u001b[34m(self, context)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Execute the step.\"\"\"\u001b[39;00m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.prompt_or_func, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    107\u001b[39m     \u001b[38;5;66;03m# LLM-based step\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._execute_llm(context)\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    110\u001b[39m     \u001b[38;5;66;03m# Function-based step\u001b[39;00m\n\u001b[32m    111\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._execute_function(context)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Coding/ailib/src/ailib/workflows/_core.py:145\u001b[39m, in \u001b[36mSimpleStep._execute_llm\u001b[39m\u001b[34m(self, context)\u001b[39m\n\u001b[32m    143\u001b[39m     \u001b[38;5;66;03m# Validate output if schema provided\u001b[39;00m\n\u001b[32m    144\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output_schema:\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Coding/ailib/src/ailib/workflows/_core.py:198\u001b[39m, in \u001b[36mSimpleStep._validate_output\u001b[39m\u001b[34m(self, output)\u001b[39m\n\u001b[32m    195\u001b[39m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    197\u001b[39m     \u001b[38;5;66;03m# If validation fails, will be caught by retry logic\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    199\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOutput validation failed - expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.output_schema.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput[:\u001b[32m200\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    200\u001b[39m     )\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSchema validation failed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Output validation failed - expected ProductAnalysis, got: This product description highlights the key features of the EcoFlow Portable Power Station, positioning it as a convenient and essential item for outdoor activities such as camping. The mention of its..."
     ]
    }
   ],
   "source": [
    "# Define expected output structure\n",
    "class ProductAnalysis(BaseModel):\n",
    "    name: str\n",
    "    category: str\n",
    "    price_range: str\n",
    "    key_features: List[str]\n",
    "    target_audience: str\n",
    "    sentiment_score: float\n",
    "\n",
    "\n",
    "# Workflow with validated outputs\n",
    "analysis_workflow = (\n",
    "    create_workflow()\n",
    "    .step(\n",
    "        \"Analyze this product description: {description}\",\n",
    "        output_schema=ProductAnalysis,  # Ensures valid structure\n",
    "        retry=2,  # Retry if validation fails\n",
    "    )\n",
    "    .step(\"Generate marketing tagline based on: {name} for {target_audience}\")\n",
    ")\n",
    "\n",
    "print(\"Created workflow with schema validation\")\n",
    "\n",
    "# Run with a real product description\n",
    "description = \"\"\"\n",
    "The EcoFlow Portable Power Station is a compact, lightweight battery pack\n",
    "perfect for camping and outdoor adventures. Features 500Wh capacity,\n",
    "solar charging capability, and multiple USB/AC outlets. Priced at $399.\n",
    "\"\"\"\n",
    "\n",
    "result = await analysis_workflow.run(description=description)\n",
    "print(f\"\\nGenerated tagline: {result}\")\n",
    "print(\n",
    "    \"\\nNote: The first step's output was automatically validated as a ProductAnalysis object!\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created composite data pipeline workflow\n"
     ]
    }
   ],
   "source": [
    "# Create reusable sub-workflows\n",
    "validation_workflow = (\n",
    "    create_workflow()\n",
    "    .step(\"Check data format\")\n",
    "    .step(\"Validate against business rules\")\n",
    "    .step(\"Ensure compliance requirements\")\n",
    ")\n",
    "\n",
    "enrichment_workflow = (\n",
    "    create_workflow()\n",
    "    .step(\"Add metadata\")\n",
    "    .step(\"Enhance with external data\")\n",
    "    .step(\"Calculate derived fields\")\n",
    ")\n",
    "\n",
    "# Compose into larger workflow\n",
    "data_pipeline = (\n",
    "    create_workflow()\n",
    "    .step(\"Extract data from source: {source}\")\n",
    "    .use(validation_workflow)  # Embed validation\n",
    "    .use(enrichment_workflow)  # Embed enrichment\n",
    "    .step(\"Load into data warehouse\")\n",
    "    .step(\"Send completion notification\")\n",
    ")\n",
    "\n",
    "print(\"Created composite data pipeline workflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Real-World Example: Customer Support Automation\n",
    "\n",
    "Let's build a complete customer support workflow that combines everything we've learned:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created comprehensive customer support automation workflow\n",
      "Workflow has 7 main steps\n",
      "Features: conditional routing, parallel search, approval gates, error handling\n"
     ]
    }
   ],
   "source": [
    "# Define response structure\n",
    "class SupportResponse(BaseModel):\n",
    "    category: str\n",
    "    priority: str\n",
    "    suggested_response: str\n",
    "    escalation_needed: bool\n",
    "    sentiment: str\n",
    "\n",
    "\n",
    "# Build comprehensive support workflow\n",
    "support_automation = (\n",
    "    create_workflow()\n",
    "    .with_state({\"tickets_processed\": 0, \"escalations\": [], \"avg_response_time\": 0})\n",
    "    # Initial analysis\n",
    "    .step(\n",
    "        \"Analyze customer message: {message}\",\n",
    "        name=\"analysis\",\n",
    "        output_schema=SupportResponse,\n",
    "        retry=2,\n",
    "    )\n",
    "    # Route based on priority\n",
    "    .if_(lambda r: r.priority == \"urgent\" or r.escalation_needed)\n",
    "    .then(\n",
    "        create_workflow()\n",
    "        # Urgent path\n",
    "        .parallel(\n",
    "            \"Search knowledge base for: {message}\",\n",
    "            \"Find similar resolved tickets\",\n",
    "            \"Check customer history\",\n",
    "        )\n",
    "        .all()\n",
    "        .step(\"Generate detailed response incorporating all findings\")\n",
    "        .require_approval(notify=[\"support-lead@company.com\"], timeout=\"30 minutes\")\n",
    "        .step(lambda ctx: ctx.state[\"escalations\"].append(ctx.analysis))\n",
    "        .build()  # Build the sub-workflow\n",
    "    )\n",
    "    .else_(\n",
    "        # Standard path\n",
    "        create_workflow()\n",
    "        .step(\"Generate automated response based on analysis\")\n",
    "        .step(\"Add personalization based on customer profile\")\n",
    "        .build()  # Build the sub-workflow\n",
    "    )\n",
    "    # Follow-up actions\n",
    "    .step(\"Send response to customer\")\n",
    "    .step(lambda ctx: {\"tickets_processed\": ctx.state[\"tickets_processed\"] + 1})\n",
    "    # Conditional follow-up\n",
    "    .if_(lambda r: \"refund\" in r.message.lower())\n",
    "    .then(\"Create refund ticket in billing system\")\n",
    "    .elif_(lambda r: \"bug\" in r.message.lower())\n",
    "    .then(\"Create issue in bug tracking system\")\n",
    "    .else_(\"Schedule follow-up in 24 hours\")\n",
    "    # Error handling\n",
    "    .on_error()\n",
    "    .do(\"Log error to monitoring system\", \"Route to human agent\")\n",
    "    .finally_do(\"Update metrics dashboard\")\n",
    ")\n",
    "\n",
    "print(\"Created comprehensive customer support automation workflow\")\n",
    "print(f\"Workflow has {len(support_automation.build().steps)} main steps\")\n",
    "print(\"Features: conditional routing, parallel search, approval gates, error handling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating blog post about: the future of remote work\n",
      "\n",
      "ðŸ“ Generated Blog Post:\n",
      "==================================================\n",
      "In today's fast-paced world, finding time to relax and unwind can be a challenge. However, taking the time to prioritize self-care is crucial for our mental and physical well-being. One way to achieve this is by creating a self-care routine that suits your lifestyle and needs.\n",
      "\n",
      "Start by identifying activities that help you feel relaxed and rejuvenated. This could include activities such as reading a book, going for a walk in nature, practicing yoga or meditation, or indulging in a hobby you enjoy. The key is to find activities that help you feel calm and centered.\n",
      "\n",
      "Incorporating self-care into your daily routine can be as simple as setting aside a few minutes each day to practice mindfulness or relaxation techniques. This could involve deep breathing exercises, taking a short walk outside, or simply taking a moment to sit quietly and reflect on your day.\n",
      "\n",
      "It's important to remember that self-care is not selfish. Taking care of yourself allows you to better care for others and improves your overall well-being. By prioritizing self-care, you are investing in your mental and physical health, which will ultimately benefit you in the long run.\n",
      "\n",
      "So, make self-care a priority in your life. Take the time to create a self-care routine that works for you and stick to it. Your mind and body will thank you for it.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Complete example: Smart content generator\n",
    "content_generator = (\n",
    "    create_workflow()\n",
    "    .step(\"Generate a blog post title about: {topic}\")\n",
    "    .step(\"Write an engaging introduction paragraph\")\n",
    "    .if_(lambda r: len(r) < 100)\n",
    "    .then(\"Expand the introduction with more detail\")\n",
    "    .else_(\"Continue with the current introduction\")\n",
    "    .parallel(\n",
    "        \"Write 3 main points\",\n",
    "        \"Find 3 relevant statistics\",\n",
    "        \"Generate a compelling conclusion\",\n",
    "    )\n",
    "    .all()\n",
    "    .step(\"Combine all sections into a complete blog post\")\n",
    ")\n",
    "\n",
    "# Run it!\n",
    "topic = \"the future of remote work\"\n",
    "print(f\"Generating blog post about: {topic}\\n\")\n",
    "\n",
    "result = await content_generator.run(topic=topic)\n",
    "print(\"ðŸ“ Generated Blog Post:\")\n",
    "print(\"=\" * 50)\n",
    "print(result)\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try It Yourself!\n",
    "\n",
    "Here's a complete example you can run right now:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices\n",
    "\n",
    "1. **Start Simple**: Begin with basic sequential workflows\n",
    "2. **Name Your Steps**: Use descriptive names for better debugging\n",
    "3. **Validate Important Data**: Use schemas for critical transformations\n",
    "4. **Handle Errors Gracefully**: Add retries and fallbacks\n",
    "5. **Use Parallel Execution**: For independent operations\n",
    "6. **Compose and Reuse**: Build a library of workflow components\n",
    "\n",
    "## Summary\n",
    "\n",
    "AILib's workflow system provides powerful orchestration capabilities while maintaining simplicity:\n",
    "\n",
    "- **Simple API**: Start with one-liners, add complexity as needed\n",
    "- **Flexible Control Flow**: Conditions, loops, parallel execution\n",
    "- **Robust Error Handling**: Retries, fallbacks, custom handlers\n",
    "- **Type Safety**: Schema validation with Pydantic\n",
    "- **Human Integration**: Approval gates and interventions\n",
    "- **Composable**: Build complex workflows from simple parts\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Explore the [Workflow API Reference](../../docs/workflows/api-reference.md)\n",
    "- Check out [Advanced Examples](../workflow_advanced.py)\n",
    "- Build your own custom workflows!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
