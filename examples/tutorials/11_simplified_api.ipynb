{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AILib Tutorial 11: Simplified API - Vercel AI SDK Style\n",
    "\n",
    "This tutorial introduces AILib's new simplified API, inspired by Vercel AI SDK. Learn how to:\n",
    "\n",
    "- Use factory functions for quick setup\n",
    "- Build agents and chains with minimal code\n",
    "- Understand the philosophy of progressive disclosure\n",
    "- Migrate from the old verbose API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Philosophy: Simple by Default\n",
    "\n",
    "AILib now offers two ways to create objects:\n",
    "\n",
    "1. **Factory Functions** (Recommended): Simple, validated, and safe\n",
    "2. **Direct Instantiation**: More control, no validation\n",
    "\n",
    "Let's see the difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ailib import create_agent, create_chain, create_session\n",
    "from ailib import Agent, Chain, Session  # Direct classes\n",
    "import os\n",
    "\n",
    "# Make sure you have your API key set\n",
    "# os.environ['OPENAI_API_KEY'] = 'your-key-here'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Agents - The New Way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old way (verbose - LangChain style)\n",
    "# from ailib import OpenAIClient, Agent\n",
    "# client = OpenAIClient(model=\"gpt-4\")\n",
    "# agent = Agent(llm=client, max_steps=10, verbose=True)\n",
    "\n",
    "# New way (simple - Vercel AI SDK style)\n",
    "agent = create_agent(\"assistant\", model=\"gpt-4\", verbose=True)\n",
    "\n",
    "# That's it! The factory function handles:\n",
    "# - Creating the LLM client\n",
    "# - Setting up defaults\n",
    "# - Validating parameters\n",
    "\n",
    "result = agent.run(\"What is 2 + 2?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Tools - Clean and Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ailib import tool\n",
    "\n",
    "# Define tools with the decorator\n",
    "@tool\n",
    "def calculate(expression: str) -> float:\n",
    "    \"\"\"Evaluate a mathematical expression.\"\"\"\n",
    "    try:\n",
    "        return float(eval(expression))\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get the weather for a city.\"\"\"\n",
    "    # Mock implementation\n",
    "    return f\"The weather in {city} is sunny and 72Â°F\"\n",
    "\n",
    "# Create agent with tools in one line\n",
    "agent_with_tools = create_agent(\n",
    "    \"weather_assistant\",\n",
    "    tools=[calculate, get_weather],\n",
    "    instructions=\"You are a helpful assistant that can check weather and do math.\"\n",
    ")\n",
    "\n",
    "# Test it\n",
    "result = agent_with_tools.run(\n",
    "    \"What's the weather in Paris? Also, what's 15% of 250?\"\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Chains - No More Boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old way: Create client, then chain, then add steps...\n",
    "# client = OpenAIClient()\n",
    "# chain = Chain(client)\n",
    "# chain.add_system(\"You are a translator\")\n",
    "# chain.add_user(\"Translate to Spanish: {text}\")\n",
    "\n",
    "# New way: Just list your prompts!\n",
    "translation_chain = create_chain(\n",
    "    \"You are a professional translator.\",\n",
    "    \"Translate this to Spanish: {text}\",\n",
    "    \"Now make it more formal\",\n",
    "    \"Finally, add a polite greeting at the beginning\"\n",
    ")\n",
    "\n",
    "result = translation_chain.run(text=\"Hello, how are you today?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session Management - With Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a session with validation\n",
    "session = create_session(\n",
    "    session_id=\"demo-session\",\n",
    "    max_messages=50,\n",
    "    metadata={\"user\": \"demo\", \"purpose\": \"tutorial\"}\n",
    ")\n",
    "\n",
    "# Add messages\n",
    "session.add_system_message(\"You are a helpful tutor\")\n",
    "session.add_user_message(\"Explain quantum computing\")\n",
    "\n",
    "# Use with a client\n",
    "from ailib import OpenAIClient\n",
    "client = OpenAIClient()\n",
    "\n",
    "response = client.complete(session.get_messages())\n",
    "session.add_assistant_message(response.content)\n",
    "\n",
    "print(f\"Session has {len(session)} messages\")\n",
    "print(f\"Session ID: {session.session_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Options Still Available\n",
    "\n",
    "The simplified API doesn't limit you - all options are available as kwargs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fully customized agent\n",
    "advanced_agent = create_agent(\n",
    "    \"advanced\",\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0.2,\n",
    "    max_steps=20,\n",
    "    verbose=True,\n",
    "    memory_size=50,\n",
    "    return_intermediate_steps=True,\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),  # Can override\n",
    "    instructions=\"\"\"You are an expert researcher. \n",
    "    Always cite your sources and think step by step.\"\"\"\n",
    ")\n",
    "\n",
    "print(f\"Agent configured with temperature: {advanced_agent.temperature}\")\n",
    "print(f\"Max steps: {advanced_agent.max_steps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct Instantiation for Full Control\n",
    "\n",
    "When you need to bypass validation or have special requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct instantiation - no validation!\n",
    "from ailib import Agent, OpenAIClient\n",
    "\n",
    "# This allows \"invalid\" values\n",
    "custom_agent = Agent(\n",
    "    llm=OpenAIClient(),\n",
    "    temperature=5.0,  # Normally limited to 0-2\n",
    "    max_steps=1000    # Very high!\n",
    ")\n",
    "\n",
    "print(f\"Agent with temperature {custom_agent.temperature} created!\")\n",
    "print(\"Note: Use direct instantiation carefully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison: Old vs New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the difference in code length and complexity\n",
    "\n",
    "print(\"=== OLD WAY (LangChain style) ===\")\n",
    "print('''\n",
    "from ailib import OpenAIClient, Agent, Chain\n",
    "from ailib.validation import AgentConfig, ChainConfig\n",
    "\n",
    "# Create client\n",
    "client = OpenAIClient(model=\"gpt-4\", temperature=0.7)\n",
    "\n",
    "# Create config\n",
    "config = AgentConfig(\n",
    "    name=\"assistant\",\n",
    "    model=\"gpt-4\",\n",
    "    max_iterations=10,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# Create agent\n",
    "agent = Agent(llm=client, config=config)\n",
    "\n",
    "# Create chain\n",
    "chain = Chain(llm=client)\n",
    "chain.add_system(\"You are helpful\")\n",
    "chain.add_user(\"Hello\")\n",
    "''')\n",
    "\n",
    "print(\"\\n=== NEW WAY (Vercel AI SDK style) ===\")\n",
    "print('''\n",
    "from ailib import create_agent, create_chain\n",
    "\n",
    "# Create agent\n",
    "agent = create_agent(\"assistant\", model=\"gpt-4\")\n",
    "\n",
    "# Create chain\n",
    "chain = create_chain(\"You are helpful\", \"Hello\")\n",
    "''')\n",
    "\n",
    "print(\"\\nâœ¨ Much simpler and cleaner!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Example: Building a Research Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's build something real with the new API\n",
    "\n",
    "@tool\n",
    "def search_papers(query: str, limit: int = 5) -> str:\n",
    "    \"\"\"Search for academic papers on a topic.\"\"\"\n",
    "    # Mock implementation\n",
    "    papers = [\n",
    "        f\"Paper {i+1}: Study on {query} - Published 2024\"\n",
    "        for i in range(limit)\n",
    "    ]\n",
    "    return \"\\n\".join(papers)\n",
    "\n",
    "@tool\n",
    "def summarize_text(text: str, max_words: int = 100) -> str:\n",
    "    \"\"\"Summarize text to a specific length.\"\"\"\n",
    "    words = text.split()[:max_words]\n",
    "    return \" \".join(words) + \"...\"\n",
    "\n",
    "@tool\n",
    "def save_research(title: str, content: str) -> str:\n",
    "    \"\"\"Save research findings to a file.\"\"\"\n",
    "    # Mock implementation\n",
    "    return f\"Research '{title}' saved successfully!\"\n",
    "\n",
    "# Create a research assistant in one line!\n",
    "research_assistant = create_agent(\n",
    "    \"researcher\",\n",
    "    model=\"gpt-4\",\n",
    "    tools=[search_papers, summarize_text, save_research],\n",
    "    instructions=\"\"\"You are an academic research assistant.\n",
    "    When asked about a topic:\n",
    "    1. Search for relevant papers\n",
    "    2. Summarize key findings\n",
    "    3. Save important research\n",
    "    Always provide citations and be thorough.\"\"\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Use it\n",
    "result = research_assistant.run(\n",
    "    \"Research the latest developments in quantum computing\"\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Migration Guide: Updating Your Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have existing code, here's how to migrate:\n",
    "\n",
    "# OLD CODE:\n",
    "# from ailib import OpenAIClient, Agent\n",
    "# client = OpenAIClient(model=\"gpt-4\")\n",
    "# agent = Agent(llm=client, verbose=True)\n",
    "\n",
    "# NEW CODE:\n",
    "from ailib import create_agent\n",
    "agent = create_agent(\"my_agent\", model=\"gpt-4\", verbose=True)\n",
    "\n",
    "# The functionality is the same, just simpler!\n",
    "\n",
    "# For chains:\n",
    "# OLD: chain = Chain(client).add_user(\"Hello\")\n",
    "# NEW: \n",
    "chain = create_chain(\"Hello\")\n",
    "\n",
    "# For sessions:\n",
    "# OLD: session = Session(session_id=\"abc\")\n",
    "# NEW:\n",
    "session = create_session(session_id=\"abc\")\n",
    "\n",
    "print(\"âœ… Migration is easy - just use the create_* functions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The new simplified API makes AILib much easier to use:\n",
    "\n",
    "- âœ… **Factory functions** for quick setup\n",
    "- âœ… **No boilerplate** - just the essentials\n",
    "- âœ… **Validation built-in** for safety\n",
    "- âœ… **All options available** through kwargs\n",
    "- âœ… **Direct instantiation** when you need control\n",
    "\n",
    "This follows the Vercel AI SDK philosophy:\n",
    "- Simple by default\n",
    "- Progressive disclosure of complexity\n",
    "- Power when you need it\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Try the [Safety and Moderation](12_safety_and_moderation.ipynb) features\n",
    "- Explore [Tracing and Debugging](13_tracing_and_debugging.ipynb)\n",
    "- Build something awesome with the simplified API!\n",
    "\n",
    "Happy coding! ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
