{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AILib Tutorial 6: Chains - Sequential Operations\n",
    "\n",
    "Chains allow you to connect multiple operations in sequence, creating powerful workflows. In this tutorial, you'll learn:\n",
    "\n",
    "- Creating and running basic chains\n",
    "- Passing data between chain steps\n",
    "- Building complex multi-step workflows\n",
    "- Error handling in chains\n",
    "- Async chain operations\n",
    "- Real-world chain patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Let's import what we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ailib import OpenAIClient\n",
    "from ailib.chains import Chain\n",
    "from ailib.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Create a client\n",
    "client = OpenAIClient()\n",
    "print(\"Ready to build chains!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Chain Usage\n",
    "\n",
    "Chains connect operations that run in sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple chain\n",
    "chain = Chain()\n",
    "\n",
    "# Add steps to the chain\n",
    "chain.add_step(\n",
    "    \"generate_idea\",\n",
    "    lambda: client.complete(\"Generate a creative business idea for a mobile app\")\n",
    ")\n",
    "\n",
    "chain.add_step(\n",
    "    \"analyze_feasibility\",\n",
    "    lambda idea: client.complete(f\"Analyze the feasibility of this idea: {idea}\")\n",
    ")\n",
    "\n",
    "chain.add_step(\n",
    "    \"create_pitch\",\n",
    "    lambda analysis: client.complete(f\"Create a 30-second elevator pitch based on: {analysis}\")\n",
    ")\n",
    "\n",
    "# Run the chain\n",
    "result = chain.run()\n",
    "\n",
    "print(\"Chain Result:\")\n",
    "print(result)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Access intermediate results\n",
    "print(\"Intermediate Results:\")\n",
    "for step_name, step_result in chain.results.items():\n",
    "    print(f\"\\n{step_name}:\")\n",
    "    print(step_result[:150] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fluent API\n",
    "\n",
    "Chains support a fluent API for cleaner code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a chain using fluent API\n",
    "result = (Chain()\n",
    "    .add_step(\"topic\", lambda: \"artificial intelligence in healthcare\")\n",
    "    .add_step(\"research\", lambda topic: client.complete(\n",
    "        f\"List 3 current challenges in {topic}\"\n",
    "    ))\n",
    "    .add_step(\"solutions\", lambda research: client.complete(\n",
    "        f\"Based on these challenges: {research}\\n\\nPropose innovative solutions.\"\n",
    "    ))\n",
    "    .add_step(\"summary\", lambda solutions: client.complete(\n",
    "        f\"Summarize these solutions in 2 sentences: {solutions}\"\n",
    "    ))\n",
    "    .run()\n",
    ")\n",
    "\n",
    "print(\"Final Summary:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chains with Templates\n",
    "\n",
    "Combine chains with prompt templates for more control:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define templates for each step\n",
    "analysis_template = PromptTemplate(\n",
    "    \"\"\"Analyze this text for {aspect}:\n",
    "    \n",
    "    Text: {text}\n",
    "    \n",
    "    Provide a detailed analysis focusing on {focus}.\"\"\"\n",
    ")\n",
    "\n",
    "improvement_template = PromptTemplate(\n",
    "    \"\"\"Based on this analysis: {analysis}\n",
    "    \n",
    "    Suggest {num_suggestions} specific improvements.\n",
    "    Format as a numbered list.\"\"\"\n",
    ")\n",
    "\n",
    "# Create a text improvement chain\n",
    "def create_text_improvement_chain(text, aspect=\"clarity\", focus=\"readability\"):\n",
    "    return (Chain()\n",
    "        .add_step(\"analyze\", lambda: client.complete(\n",
    "            analysis_template.format(\n",
    "                text=text,\n",
    "                aspect=aspect,\n",
    "                focus=focus\n",
    "            )\n",
    "        ))\n",
    "        .add_step(\"improve\", lambda analysis: client.complete(\n",
    "            improvement_template.format(\n",
    "                analysis=analysis,\n",
    "                num_suggestions=3\n",
    "            )\n",
    "        ))\n",
    "        .add_step(\"apply\", lambda suggestions: client.complete(\n",
    "            f\"Apply these improvements to the original text:\\n{suggestions}\\n\\nOriginal: {text}\"\n",
    "        ))\n",
    "    )\n",
    "\n",
    "# Use the chain\n",
    "sample_text = \"The implementation of the new system will be done by the team soon.\"\n",
    "improvement_chain = create_text_improvement_chain(sample_text, \"clarity\", \"specificity\")\n",
    "improved_text = improvement_chain.run()\n",
    "\n",
    "print(\"Original Text:\")\n",
    "print(sample_text)\n",
    "print(\"\\nImproved Text:\")\n",
    "print(improved_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation Chains\n",
    "\n",
    "Chains can transform data through multiple steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data processing chain\n",
    "def create_data_chain():\n",
    "    return Chain()\n",
    "\n",
    "# Step 1: Generate raw data\n",
    "def generate_data():\n",
    "    response = client.complete(\n",
    "        \"\"\"Generate a JSON array of 5 products with fields: \n",
    "        name, price, category, rating. \n",
    "        Make it realistic e-commerce data.\"\"\"\n",
    "    )\n",
    "    # Extract JSON from response\n",
    "    try:\n",
    "        # Find JSON in response\n",
    "        import re\n",
    "        json_match = re.search(r'\\[.*\\]', response, re.DOTALL)\n",
    "        if json_match:\n",
    "            return json.loads(json_match.group())\n",
    "    except:\n",
    "        pass\n",
    "    return [{\"name\": \"Sample\", \"price\": 10, \"category\": \"test\", \"rating\": 4}]\n",
    "\n",
    "# Step 2: Filter products\n",
    "def filter_products(products):\n",
    "    # Filter products with rating >= 4\n",
    "    filtered = [p for p in products if p.get('rating', 0) >= 4]\n",
    "    return filtered\n",
    "\n",
    "# Step 3: Analyze filtered data\n",
    "def analyze_products(products):\n",
    "    analysis_prompt = f\"\"\"Analyze these products and provide insights:\n",
    "    {json.dumps(products, indent=2)}\n",
    "    \n",
    "    Include: average price, popular categories, and recommendations.\"\"\"\n",
    "    return client.complete(analysis_prompt)\n",
    "\n",
    "# Step 4: Generate report\n",
    "def generate_report(analysis):\n",
    "    report_prompt = f\"\"\"Convert this analysis into a professional business report:\n",
    "    {analysis}\n",
    "    \n",
    "    Format with sections: Executive Summary, Key Findings, Recommendations.\"\"\"\n",
    "    return client.complete(report_prompt)\n",
    "\n",
    "# Build and run the chain\n",
    "data_chain = (Chain()\n",
    "    .add_step(\"generate\", generate_data)\n",
    "    .add_step(\"filter\", filter_products)\n",
    "    .add_step(\"analyze\", analyze_products)\n",
    "    .add_step(\"report\", generate_report)\n",
    ")\n",
    "\n",
    "report = data_chain.run()\n",
    "print(\"Generated Report:\")\n",
    "print(report[:500] + \"...\")\n",
    "\n",
    "# Show intermediate data\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"Filtered Products:\")\n",
    "print(json.dumps(data_chain.results.get('filter', []), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Handling in Chains\n",
    "\n",
    "Implement robust error handling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chain with error handling\n",
    "class SafeChain(Chain):\n",
    "    \"\"\"Chain with built-in error handling.\"\"\"\n",
    "    \n",
    "    def __init__(self, on_error=\"continue\"):\n",
    "        super().__init__()\n",
    "        self.on_error = on_error  # \"continue\", \"stop\", or callable\n",
    "        self.errors = {}\n",
    "    \n",
    "    def run(self, initial_input=None):\n",
    "        \"\"\"Run chain with error handling.\"\"\"\n",
    "        result = initial_input\n",
    "        \n",
    "        for step_name, step_func in self.steps:\n",
    "            try:\n",
    "                # Run step\n",
    "                if result is None:\n",
    "                    result = step_func()\n",
    "                else:\n",
    "                    result = step_func(result)\n",
    "                \n",
    "                # Store result\n",
    "                self.results[step_name] = result\n",
    "                \n",
    "            except Exception as e:\n",
    "                # Store error\n",
    "                self.errors[step_name] = str(e)\n",
    "                \n",
    "                # Handle error based on policy\n",
    "                if self.on_error == \"stop\":\n",
    "                    raise\n",
    "                elif self.on_error == \"continue\":\n",
    "                    result = f\"Error in {step_name}: {str(e)}\"\n",
    "                elif callable(self.on_error):\n",
    "                    result = self.on_error(step_name, e, result)\n",
    "        \n",
    "        return result\n",
    "\n",
    "# Test error handling\n",
    "def risky_operation(x):\n",
    "    if \"error\" in x.lower():\n",
    "        raise ValueError(\"Operation failed!\")\n",
    "    return f\"Processed: {x}\"\n",
    "\n",
    "# Create chain with error recovery\n",
    "safe_chain = SafeChain(on_error=\"continue\")\n",
    "safe_chain.add_step(\"step1\", lambda: \"Starting data\")\n",
    "safe_chain.add_step(\"step2\", lambda x: x + \" -> adding more\")\n",
    "safe_chain.add_step(\"step3\", lambda x: risky_operation(x + \" ERROR\"))  # This will fail\n",
    "safe_chain.add_step(\"step4\", lambda x: f\"Final: {x}\")\n",
    "\n",
    "result = safe_chain.run()\n",
    "print(\"Chain completed with result:\")\n",
    "print(result)\n",
    "print(\"\\nErrors encountered:\")\n",
    "print(safe_chain.errors)\n",
    "\n",
    "# Custom error handler\n",
    "def custom_error_handler(step_name, error, last_result):\n",
    "    print(f\"Handling error in {step_name}: {error}\")\n",
    "    return f\"Recovered from {step_name} error\"\n",
    "\n",
    "custom_chain = SafeChain(on_error=custom_error_handler)\n",
    "custom_chain.add_step(\"risky\", lambda: risky_operation(\"This has ERROR in it\"))\n",
    "custom_chain.add_step(\"safe\", lambda x: f\"Continued after: {x}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"Custom error handling:\")\n",
    "result = custom_chain.run()\n",
    "print(f\"Final result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Chains\n",
    "\n",
    "Create chains with conditional logic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalChain(Chain):\n",
    "    \"\"\"Chain with conditional branching.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conditions = {}\n",
    "    \n",
    "    def add_conditional_step(self, name, condition, true_func, false_func=None):\n",
    "        \"\"\"Add a step that runs based on a condition.\"\"\"\n",
    "        def conditional_wrapper(input_data):\n",
    "            if condition(input_data):\n",
    "                return true_func(input_data)\n",
    "            elif false_func:\n",
    "                return false_func(input_data)\n",
    "            else:\n",
    "                return input_data\n",
    "        \n",
    "        self.add_step(name, conditional_wrapper)\n",
    "        return self\n",
    "\n",
    "# Create a content moderation chain\n",
    "def create_moderation_chain():\n",
    "    chain = ConditionalChain()\n",
    "    \n",
    "    # Step 1: Analyze content\n",
    "    chain.add_step(\n",
    "        \"analyze\",\n",
    "        lambda text: {\n",
    "            \"text\": text,\n",
    "            \"sentiment\": client.complete(f\"Analyze sentiment of: {text}. Reply with just: positive, negative, or neutral\"),\n",
    "            \"length\": len(text)\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Step 2: Conditional processing based on sentiment\n",
    "    chain.add_conditional_step(\n",
    "        \"process_sentiment\",\n",
    "        condition=lambda data: \"negative\" in data[\"sentiment\"].lower(),\n",
    "        true_func=lambda data: {\n",
    "            **data,\n",
    "            \"action\": \"review\",\n",
    "            \"message\": client.complete(f\"Rewrite this in a more positive tone: {data['text']}\")\n",
    "        },\n",
    "        false_func=lambda data: {\n",
    "            **data,\n",
    "            \"action\": \"approve\",\n",
    "            \"message\": data[\"text\"]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Step 3: Format response\n",
    "    chain.add_step(\n",
    "        \"format\",\n",
    "        lambda data: f\"\"\"Content Analysis:\n",
    "- Original: {data['text']}\n",
    "- Sentiment: {data['sentiment']}\n",
    "- Action: {data['action']}\n",
    "- Final Message: {data['message']}\"\"\"\n",
    "    )\n",
    "    \n",
    "    return chain\n",
    "\n",
    "# Test with different inputs\n",
    "moderation_chain = create_moderation_chain()\n",
    "\n",
    "test_texts = [\n",
    "    \"This product is terrible and I hate it!\",\n",
    "    \"I love this service, it's amazing!\",\n",
    "    \"The weather is okay today.\"\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    print(f\"\\nProcessing: '{text}'\")\n",
    "    print(\"-\" * 50)\n",
    "    result = moderation_chain.run(text)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Chains\n",
    "\n",
    "Run multiple chains in parallel and combine results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParallelChain:\n",
    "    \"\"\"Run multiple chains in parallel.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.chains = {}\n",
    "    \n",
    "    def add_chain(self, name, chain):\n",
    "        \"\"\"Add a chain to run in parallel.\"\"\"\n",
    "        self.chains[name] = chain\n",
    "        return self\n",
    "    \n",
    "    def run(self, input_data=None):\n",
    "        \"\"\"Run all chains and collect results.\"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        # In production, use asyncio or threading\n",
    "        for name, chain in self.chains.items():\n",
    "            results[name] = chain.run(input_data)\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Create parallel analysis chains\n",
    "def create_analysis_chains(text):\n",
    "    # Technical analysis chain\n",
    "    technical_chain = (Chain()\n",
    "        .add_step(\"complexity\", lambda: client.complete(\n",
    "            f\"Analyze technical complexity of: {text}. Rate 1-10 with explanation.\"\n",
    "        ))\n",
    "        .add_step(\"jargon\", lambda complexity: client.complete(\n",
    "            f\"Identify technical jargon in: {text}\"\n",
    "        ))\n",
    "    )\n",
    "    \n",
    "    # Readability chain\n",
    "    readability_chain = (Chain()\n",
    "        .add_step(\"grade_level\", lambda: client.complete(\n",
    "            f\"What reading grade level is this text: {text}\"\n",
    "        ))\n",
    "        .add_step(\"simplify\", lambda level: client.complete(\n",
    "            f\"Simplify this text for general audience: {text}\"\n",
    "        ))\n",
    "    )\n",
    "    \n",
    "    # Sentiment chain\n",
    "    sentiment_chain = (Chain()\n",
    "        .add_step(\"emotion\", lambda: client.complete(\n",
    "            f\"Identify emotions in: {text}\"\n",
    "        ))\n",
    "        .add_step(\"tone\", lambda emotion: client.complete(\n",
    "            f\"Describe the overall tone of: {text}\"\n",
    "        ))\n",
    "    )\n",
    "    \n",
    "    return ParallelChain()\n",
    "        .add_chain(\"technical\", technical_chain)\n",
    "        .add_chain(\"readability\", readability_chain)\n",
    "        .add_chain(\"sentiment\", sentiment_chain)\n",
    "\n",
    "# Run parallel analysis\n",
    "sample_text = \"\"\"The quantum entanglement phenomenon demonstrates non-local correlations \n",
    "between particles, challenging our classical understanding of reality.\"\"\"\n",
    "\n",
    "parallel_analysis = create_analysis_chains(sample_text)\n",
    "results = parallel_analysis.run()\n",
    "\n",
    "print(\"Parallel Analysis Results:\")\n",
    "print(\"=\" * 50)\n",
    "for analysis_type, result in results.items():\n",
    "    print(f\"\\n{analysis_type.upper()} Analysis:\")\n",
    "    print(result[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain Composition\n",
    "\n",
    "Compose complex chains from simpler ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create reusable chain components\n",
    "class ChainLibrary:\n",
    "    \"\"\"Library of reusable chain components.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def translation_chain(target_language):\n",
    "        \"\"\"Create a translation chain.\"\"\"\n",
    "        return Chain().add_step(\n",
    "            \"translate\",\n",
    "            lambda text: client.complete(f\"Translate to {target_language}: {text}\")\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def summary_chain(length=\"brief\"):\n",
    "        \"\"\"Create a summarization chain.\"\"\"\n",
    "        return Chain().add_step(\n",
    "            \"summarize\",\n",
    "            lambda text: client.complete(f\"Create a {length} summary of: {text}\")\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def format_chain(format_type):\n",
    "        \"\"\"Create a formatting chain.\"\"\"\n",
    "        return Chain().add_step(\n",
    "            \"format\",\n",
    "            lambda text: client.complete(f\"Format this as {format_type}: {text}\")\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def compose(*chains):\n",
    "        \"\"\"Compose multiple chains into one.\"\"\"\n",
    "        composed = Chain()\n",
    "        \n",
    "        for i, chain in enumerate(chains):\n",
    "            for step_name, step_func in chain.steps:\n",
    "                # Rename steps to avoid conflicts\n",
    "                composed.add_step(f\"{i}_{step_name}\", step_func)\n",
    "        \n",
    "        return composed\n",
    "\n",
    "# Create a multi-language announcement chain\n",
    "announcement = \"We're launching a new AI-powered feature next week!\"\n",
    "\n",
    "# Compose chains for different purposes\n",
    "multilingual_chain = ChainLibrary.compose(\n",
    "    Chain().add_step(\"original\", lambda: announcement),\n",
    "    ChainLibrary.summary_chain(\"very brief\"),\n",
    "    ChainLibrary.translation_chain(\"Spanish\"),\n",
    "    ChainLibrary.format_chain(\"tweet\")\n",
    ")\n",
    "\n",
    "result = multilingual_chain.run()\n",
    "print(\"Multilingual Tweet:\")\n",
    "print(result)\n",
    "\n",
    "# Create a document processing pipeline\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "document = \"\"\"Artificial Intelligence is transforming industries worldwide. \n",
    "From healthcare to finance, AI applications are improving efficiency and decision-making. \n",
    "However, ethical considerations and job displacement remain significant challenges.\"\"\"\n",
    "\n",
    "processing_pipeline = ChainLibrary.compose(\n",
    "    Chain().add_step(\"input\", lambda: document),\n",
    "    ChainLibrary.summary_chain(\"one sentence\"),\n",
    "    ChainLibrary.format_chain(\"professional email subject line\")\n",
    ")\n",
    "\n",
    "email_subject = processing_pipeline.run()\n",
    "print(\"Email Subject Line:\")\n",
    "print(email_subject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-World Example: Content Pipeline\n",
    "\n",
    "Build a complete content processing pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentPipeline:\n",
    "    \"\"\"Complete content processing pipeline.\"\"\"\n",
    "    \n",
    "    def __init__(self, client):\n",
    "        self.client = client\n",
    "    \n",
    "    def create_blog_pipeline(self):\n",
    "        \"\"\"Create a blog post generation pipeline.\"\"\"\n",
    "        return (Chain()\n",
    "            # Research phase\n",
    "            .add_step(\"research\", self._research_topic)\n",
    "            .add_step(\"outline\", self._create_outline)\n",
    "            .add_step(\"draft\", self._write_draft)\n",
    "            \n",
    "            # Enhancement phase\n",
    "            .add_step(\"enhance\", self._enhance_content)\n",
    "            .add_step(\"seo\", self._optimize_seo)\n",
    "            \n",
    "            # Finalization phase\n",
    "            .add_step(\"format\", self._format_post)\n",
    "            .add_step(\"metadata\", self._generate_metadata)\n",
    "        )\n",
    "    \n",
    "    def _research_topic(self, topic):\n",
    "        \"\"\"Research the topic.\"\"\"\n",
    "        return self.client.complete(\n",
    "            f\"Research key points about '{topic}'. List 5 important aspects.\"\n",
    "        )\n",
    "    \n",
    "    def _create_outline(self, research):\n",
    "        \"\"\"Create post outline.\"\"\"\n",
    "        return self.client.complete(\n",
    "            f\"\"\"Based on this research: {research}\n",
    "            \n",
    "            Create a blog post outline with:\n",
    "            - Introduction\n",
    "            - 3-4 main sections\n",
    "            - Conclusion\"\"\"\n",
    "        )\n",
    "    \n",
    "    def _write_draft(self, outline):\n",
    "        \"\"\"Write the first draft.\"\"\"\n",
    "        return self.client.complete(\n",
    "            f\"\"\"Write a 500-word blog post based on this outline:\n",
    "            {outline}\n",
    "            \n",
    "            Make it engaging and informative.\"\"\"\n",
    "        )\n",
    "    \n",
    "    def _enhance_content(self, draft):\n",
    "        \"\"\"Enhance the content.\"\"\"\n",
    "        return self.client.complete(\n",
    "            f\"\"\"Enhance this blog post by:\n",
    "            - Adding compelling examples\n",
    "            - Improving transitions\n",
    "            - Making it more engaging\n",
    "            \n",
    "            Post: {draft}\"\"\"\n",
    "        )\n",
    "    \n",
    "    def _optimize_seo(self, content):\n",
    "        \"\"\"Optimize for SEO.\"\"\"\n",
    "        return {\n",
    "            \"content\": content,\n",
    "            \"keywords\": self.client.complete(\n",
    "                f\"Extract 5 SEO keywords from: {content[:200]}...\"\n",
    "            )\n",
    "        }\n",
    "    \n",
    "    def _format_post(self, data):\n",
    "        \"\"\"Format the final post.\"\"\"\n",
    "        return {\n",
    "            **data,\n",
    "            \"formatted\": self.client.complete(\n",
    "                f\"Format this blog post with proper headings and sections: {data['content']}\"\n",
    "            )\n",
    "        }\n",
    "    \n",
    "    def _generate_metadata(self, data):\n",
    "        \"\"\"Generate post metadata.\"\"\"\n",
    "        return {\n",
    "            **data,\n",
    "            \"title\": self.client.complete(\n",
    "                f\"Create a catchy title for this post: {data['content'][:200]}...\"\n",
    "            ),\n",
    "            \"meta_description\": self.client.complete(\n",
    "                f\"Write a 150-character meta description for: {data['content'][:200]}...\"\n",
    "            ),\n",
    "            \"tags\": self.client.complete(\n",
    "                f\"Suggest 5 tags for this post. Return as comma-separated list: {data['content'][:200]}...\"\n",
    "            )\n",
    "        }\n",
    "\n",
    "# Use the content pipeline\n",
    "pipeline = ContentPipeline(client)\n",
    "blog_chain = pipeline.create_blog_pipeline()\n",
    "\n",
    "# Generate a blog post\n",
    "topic = \"The Future of Remote Work\"\n",
    "result = blog_chain.run(topic)\n",
    "\n",
    "print(f\"Blog Post Generation Complete!\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nTitle: {result.get('title', 'N/A')}\")\n",
    "print(f\"\\nMeta Description: {result.get('meta_description', 'N/A')}\")\n",
    "print(f\"\\nTags: {result.get('tags', 'N/A')}\")\n",
    "print(f\"\\nKeywords: {result.get('keywords', 'N/A')}\")\n",
    "print(f\"\\nContent Preview:\")\n",
    "print(result.get('formatted', result.get('content', ''))[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices\n",
    "\n",
    "Tips for building effective chains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Keep steps focused and single-purpose\n",
    "good_chain = (Chain()\n",
    "    .add_step(\"parse\", lambda x: x.split(\",\"))\n",
    "    .add_step(\"clean\", lambda x: [item.strip() for item in x])\n",
    "    .add_step(\"filter\", lambda x: [item for item in x if item])\n",
    ")\n",
    "\n",
    "# 2. Use descriptive step names\n",
    "descriptive_chain = (Chain()\n",
    "    .add_step(\"fetch_user_data\", lambda id: f\"User data for {id}\")\n",
    "    .add_step(\"validate_permissions\", lambda data: f\"Validated: {data}\")\n",
    "    .add_step(\"generate_report\", lambda data: f\"Report: {data}\")\n",
    ")\n",
    "\n",
    "# 3. Handle data transformation explicitly\n",
    "def transform_chain():\n",
    "    def parse_response(response):\n",
    "        \"\"\"Parse LLM response into structured data.\"\"\"\n",
    "        # Add error handling\n",
    "        try:\n",
    "            # Parse logic here\n",
    "            return {\"parsed\": response}\n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e), \"raw\": response}\n",
    "    \n",
    "    return (Chain()\n",
    "        .add_step(\"generate\", lambda: client.complete(\"Generate data\"))\n",
    "        .add_step(\"parse\", parse_response)\n",
    "        .add_step(\"validate\", lambda x: x if \"error\" not in x else None)\n",
    "    )\n",
    "\n",
    "# 4. Create reusable chain factories\n",
    "def create_validation_chain(rules):\n",
    "    \"\"\"Factory for creating validation chains.\"\"\"\n",
    "    chain = Chain()\n",
    "    \n",
    "    for i, rule in enumerate(rules):\n",
    "        chain.add_step(f\"validate_{i}\", rule)\n",
    "    \n",
    "    return chain\n",
    "\n",
    "# 5. Log and monitor chain execution\n",
    "class MonitoredChain(Chain):\n",
    "    def run(self, initial_input=None):\n",
    "        print(f\"Starting chain with {len(self.steps)} steps\")\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        result = super().run(initial_input)\n",
    "        \n",
    "        duration = (datetime.now() - start_time).total_seconds()\n",
    "        print(f\"Chain completed in {duration:.2f} seconds\")\n",
    "        \n",
    "        return result\n",
    "\n",
    "print(\"Best practices examples created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, you learned:\n",
    "\n",
    "- âœ… How to create and run basic chains\n",
    "- âœ… How to pass data between chain steps\n",
    "- âœ… How to use the fluent API for cleaner code\n",
    "- âœ… How to combine chains with templates\n",
    "- âœ… How to handle errors in chains\n",
    "- âœ… How to create conditional and parallel chains\n",
    "- âœ… How to compose complex chains from simple ones\n",
    "- âœ… Best practices for chain design\n",
    "\n",
    "Chains are powerful for:\n",
    "- Building multi-step workflows\n",
    "- Processing data through multiple transformations\n",
    "- Creating reusable processing pipelines\n",
    "- Orchestrating complex AI operations\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Continue learning with:\n",
    "\n",
    "- **Tutorial 7: Tools and Decorators** - Extend agent capabilities\n",
    "- **Tutorial 8: Agents** - Build autonomous AI agents\n",
    "- **Tutorial 9: Advanced Features** - Async operations and more\n",
    "\n",
    "Happy chaining! ðŸ”—"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
