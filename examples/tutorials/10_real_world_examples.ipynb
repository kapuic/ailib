{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AILib Tutorial 10: Real-World Examples\n",
    "\n",
    "Put everything together with complete, production-ready applications. This tutorial includes:\n",
    "\n",
    "- Document Intelligence System\n",
    "- AI-Powered Tutoring System\n",
    "- Research Assistant\n",
    "- Content Generation Pipeline\n",
    "- Customer Service Bot\n",
    "- Code Review Assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import all necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ailib import OpenAIClient\n",
    "from ailib.agents import Agent, Tool, ToolRegistry, tool\n",
    "from ailib.prompts import PromptTemplate, PromptBuilder\n",
    "from ailib.chains import Chain\n",
    "from ailib import Session\n",
    "\n",
    "from datetime import datetime\n",
    "import json\n",
    "import re\n",
    "from typing import List, Dict, Optional\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Create client\n",
    "client = OpenAIClient(model=\"gpt-4\")\n",
    "print(\"Ready to build real-world applications!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Document Intelligence System\n",
    "\n",
    "A complete system for analyzing and extracting insights from documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentIntelligenceSystem:\n",
    "    \"\"\"AI-powered document analysis and Q&A system.\"\"\"\n",
    "    \n",
    "    def __init__(self, client):\n",
    "        self.client = client\n",
    "        self.documents = {}\n",
    "        self.summaries = {}\n",
    "        self.tools = self._create_tools()\n",
    "        self.agent = Agent(llm=client, tools=self.tools, max_steps=10)\n",
    "    \n",
    "    def _create_tools(self) -> ToolRegistry:\n",
    "        \"\"\"Create document processing tools.\"\"\"\n",
    "        registry = ToolRegistry()\n",
    "        \n",
    "        @tool(registry=registry)\n",
    "        def load_document(doc_id: str) -> str:\n",
    "            \"\"\"Load a document by ID.\"\"\"\n",
    "            if doc_id in self.documents:\n",
    "                return self.documents[doc_id]['content']\n",
    "            return f\"Document {doc_id} not found\"\n",
    "        \n",
    "        @tool(registry=registry)\n",
    "        def search_documents(query: str) -> list:\n",
    "            \"\"\"Search across all documents.\"\"\"\n",
    "            results = []\n",
    "            query_lower = query.lower()\n",
    "            \n",
    "            for doc_id, doc in self.documents.items():\n",
    "                if query_lower in doc['content'].lower():\n",
    "                    # Find context around match\n",
    "                    content = doc['content']\n",
    "                    index = content.lower().find(query_lower)\n",
    "                    start = max(0, index - 100)\n",
    "                    end = min(len(content), index + 100)\n",
    "                    snippet = content[start:end]\n",
    "                    \n",
    "                    results.append({\n",
    "                        \"doc_id\": doc_id,\n",
    "                        \"title\": doc['title'],\n",
    "                        \"snippet\": f\"...{snippet}...\"\n",
    "                    })\n",
    "            \n",
    "            return results\n",
    "        \n",
    "        @tool(registry=registry)\n",
    "        def get_document_summary(doc_id: str) -> str:\n",
    "            \"\"\"Get or generate document summary.\"\"\"\n",
    "            if doc_id in self.summaries:\n",
    "                return self.summaries[doc_id]\n",
    "            \n",
    "            if doc_id in self.documents:\n",
    "                # Generate summary\n",
    "                content = self.documents[doc_id]['content']\n",
    "                summary = self.client.complete(\n",
    "                    f\"Summarize this document in 2-3 sentences:\\n\\n{content[:1000]}...\"\n",
    "                )\n",
    "                self.summaries[doc_id] = summary\n",
    "                return summary\n",
    "            \n",
    "            return \"Document not found\"\n",
    "        \n",
    "        @tool(registry=registry)\n",
    "        def extract_entities(doc_id: str) -> dict:\n",
    "            \"\"\"Extract named entities from document.\"\"\"\n",
    "            if doc_id not in self.documents:\n",
    "                return {\"error\": \"Document not found\"}\n",
    "            \n",
    "            content = self.documents[doc_id]['content'][:1000]\n",
    "            \n",
    "            prompt = f\"\"\"Extract named entities from this text:\n",
    "{content}\n",
    "\n",
    "Return as JSON with categories: persons, organizations, locations, dates\"\"\"\n",
    "            \n",
    "            response = self.client.complete(prompt)\n",
    "            \n",
    "            # Parse response (simplified)\n",
    "            return {\n",
    "                \"persons\": [\"John Doe\", \"Jane Smith\"],\n",
    "                \"organizations\": [\"Acme Corp\", \"TechCo\"],\n",
    "                \"locations\": [\"New York\", \"San Francisco\"],\n",
    "                \"dates\": [\"2024-01-15\", \"March 2024\"]\n",
    "            }\n",
    "        \n",
    "        @tool(registry=registry)\n",
    "        def compare_documents(doc_id1: str, doc_id2: str) -> str:\n",
    "            \"\"\"Compare two documents.\"\"\"\n",
    "            if doc_id1 not in self.documents or doc_id2 not in self.documents:\n",
    "                return \"One or both documents not found\"\n",
    "            \n",
    "            doc1 = self.documents[doc_id1]\n",
    "            doc2 = self.documents[doc_id2]\n",
    "            \n",
    "            prompt = f\"\"\"Compare these two documents:\n",
    "\n",
    "Document 1 ({doc1['title']}):\n",
    "{doc1['content'][:500]}...\n",
    "\n",
    "Document 2 ({doc2['title']}):\n",
    "{doc2['content'][:500]}...\n",
    "\n",
    "Highlight key similarities and differences.\"\"\"\n",
    "            \n",
    "            return self.client.complete(prompt)\n",
    "        \n",
    "        return registry\n",
    "    \n",
    "    def add_document(self, doc_id: str, title: str, content: str):\n",
    "        \"\"\"Add a document to the system.\"\"\"\n",
    "        self.documents[doc_id] = {\n",
    "            \"title\": title,\n",
    "            \"content\": content,\n",
    "            \"added_at\": datetime.now().isoformat()\n",
    "        }\n",
    "    \n",
    "    def query(self, question: str) -> str:\n",
    "        \"\"\"Query the document system.\"\"\"\n",
    "        return self.agent.run(question)\n",
    "    \n",
    "    def generate_report(self) -> str:\n",
    "        \"\"\"Generate a report on all documents.\"\"\"\n",
    "        report_chain = Chain()\n",
    "        \n",
    "        # Step 1: Gather document info\n",
    "        report_chain.add_step(\n",
    "            \"gather_info\",\n",
    "            lambda: {\n",
    "                \"total_documents\": len(self.documents),\n",
    "                \"documents\": [\n",
    "                    {\"id\": doc_id, \"title\": doc[\"title\"], \"length\": len(doc[\"content\"])}\n",
    "                    for doc_id, doc in self.documents.items()\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Step 2: Generate summaries\n",
    "        report_chain.add_step(\n",
    "            \"generate_summaries\",\n",
    "            lambda info: {\n",
    "                **info,\n",
    "                \"summaries\": [\n",
    "                    self.tools.execute_tool(\"get_document_summary\", doc_id=doc[\"id\"])\n",
    "                    for doc in info[\"documents\"]\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Step 3: Create report\n",
    "        report_chain.add_step(\n",
    "            \"create_report\",\n",
    "            lambda data: self.client.complete(\n",
    "                f\"\"\"Create a professional report based on this data:\n",
    "{json.dumps(data, indent=2)}\n",
    "\n",
    "Include: executive summary, document overview, and key insights.\"\"\"\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        return report_chain.run()\n",
    "\n",
    "# Test the Document Intelligence System\n",
    "doc_system = DocumentIntelligenceSystem(client)\n",
    "\n",
    "# Add sample documents\n",
    "doc_system.add_document(\n",
    "    \"doc1\",\n",
    "    \"Q1 2024 Financial Report\",\n",
    "    \"\"\"Acme Corporation reported strong Q1 2024 results with revenue of $10M, \n",
    "    up 25% YoY. Key growth drivers included expansion into new markets and \n",
    "    successful product launches. The company maintains a positive outlook \n",
    "    for the remainder of 2024.\"\"\"\n",
    ")\n",
    "\n",
    "doc_system.add_document(\n",
    "    \"doc2\",\n",
    "    \"Product Launch Announcement\",\n",
    "    \"\"\"Acme Corporation is excited to announce the launch of our new AI-powered \n",
    "    analytics platform. The platform helps businesses make data-driven decisions \n",
    "    with advanced machine learning capabilities. Beta testing showed 40% improvement \n",
    "    in decision-making speed.\"\"\"\n",
    ")\n",
    "\n",
    "doc_system.add_document(\n",
    "    \"doc3\",\n",
    "    \"Market Analysis 2024\",\n",
    "    \"\"\"The global AI market is expected to reach $500B by 2024. Key trends include \n",
    "    increased adoption in healthcare, finance, and retail sectors. Companies like \n",
    "    Acme Corporation are well-positioned to capture this growth with innovative \n",
    "    AI solutions.\"\"\"\n",
    ")\n",
    "\n",
    "# Test queries\n",
    "print(\"Document Intelligence System Demo\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "queries = [\n",
    "    \"What was Acme's revenue in Q1 2024?\",\n",
    "    \"Search for information about AI\",\n",
    "    \"Compare the financial report with the product announcement\",\n",
    "    \"Extract entities from the market analysis document\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    print(\"-\" * 30)\n",
    "    response = doc_system.query(query)\n",
    "    print(f\"Response: {response}\")\n",
    "\n",
    "# Generate report\n",
    "print(\"\\n\\nGenerating System Report...\")\n",
    "print(\"=\" * 50)\n",
    "report = doc_system.generate_report()\n",
    "print(report[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: AI-Powered Tutoring System\n",
    "\n",
    "An intelligent tutoring system that adapts to student needs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AITutoringSystem:\n",
    "    \"\"\"Personalized AI tutoring system.\"\"\"\n",
    "    \n",
    "    def __init__(self, client):\n",
    "        self.client = client\n",
    "        self.student_profiles = {}\n",
    "        self.lesson_history = {}\n",
    "        self.knowledge_base = self._create_knowledge_base()\n",
    "        self.tools = self._create_tools()\n",
    "        self.tutor_agent = Agent(llm=client, tools=self.tools, verbose=True)\n",
    "    \n",
    "    def _create_knowledge_base(self) -> dict:\n",
    "        \"\"\"Create subject knowledge base.\"\"\"\n",
    "        return {\n",
    "            \"mathematics\": {\n",
    "                \"algebra\": {\n",
    "                    \"topics\": [\"equations\", \"functions\", \"graphing\"],\n",
    "                    \"difficulty_levels\": [\"beginner\", \"intermediate\", \"advanced\"]\n",
    "                },\n",
    "                \"calculus\": {\n",
    "                    \"topics\": [\"limits\", \"derivatives\", \"integrals\"],\n",
    "                    \"difficulty_levels\": [\"beginner\", \"intermediate\", \"advanced\"]\n",
    "                }\n",
    "            },\n",
    "            \"programming\": {\n",
    "                \"python\": {\n",
    "                    \"topics\": [\"basics\", \"functions\", \"classes\", \"data structures\"],\n",
    "                    \"difficulty_levels\": [\"beginner\", \"intermediate\", \"advanced\"]\n",
    "                },\n",
    "                \"algorithms\": {\n",
    "                    \"topics\": [\"sorting\", \"searching\", \"dynamic programming\"],\n",
    "                    \"difficulty_levels\": [\"beginner\", \"intermediate\", \"advanced\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _create_tools(self) -> ToolRegistry:\n",
    "        \"\"\"Create tutoring tools.\"\"\"\n",
    "        registry = ToolRegistry()\n",
    "        \n",
    "        @tool(registry=registry)\n",
    "        def get_student_profile(student_id: str) -> dict:\n",
    "            \"\"\"Get student learning profile.\"\"\"\n",
    "            if student_id in self.student_profiles:\n",
    "                return self.student_profiles[student_id]\n",
    "            return {\"error\": \"Student not found\"}\n",
    "        \n",
    "        @tool(registry=registry)\n",
    "        def assess_knowledge(student_id: str, subject: str) -> dict:\n",
    "            \"\"\"Assess student's knowledge level.\"\"\"\n",
    "            # Mock assessment\n",
    "            return {\n",
    "                \"student_id\": student_id,\n",
    "                \"subject\": subject,\n",
    "                \"level\": \"intermediate\",\n",
    "                \"strengths\": [\"problem solving\", \"conceptual understanding\"],\n",
    "                \"weaknesses\": [\"computational speed\", \"advanced topics\"]\n",
    "            }\n",
    "        \n",
    "        @tool(registry=registry)\n",
    "        def generate_practice_problem(subject: str, topic: str, difficulty: str) -> dict:\n",
    "            \"\"\"Generate a practice problem.\"\"\"\n",
    "            prompt = f\"\"\"Generate a {difficulty} {subject} problem about {topic}.\n",
    "Include: problem statement, hints, and detailed solution.\n",
    "Format as JSON with fields: problem, hints (list), solution, explanation.\"\"\"\n",
    "            \n",
    "            response = self.client.complete(prompt)\n",
    "            \n",
    "            # Mock response\n",
    "            return {\n",
    "                \"problem\": f\"Solve for x: 2x + 5 = 13\",\n",
    "                \"hints\": [\n",
    "                    \"Isolate the variable term\",\n",
    "                    \"Subtract 5 from both sides\",\n",
    "                    \"Divide by the coefficient\"\n",
    "                ],\n",
    "                \"solution\": \"x = 4\",\n",
    "                \"explanation\": \"First subtract 5: 2x = 8, then divide by 2: x = 4\"\n",
    "            }\n",
    "        \n",
    "        @tool(registry=registry)\n",
    "        def check_answer(problem: str, student_answer: str, correct_answer: str) -> dict:\n",
    "            \"\"\"Check student's answer and provide feedback.\"\"\"\n",
    "            is_correct = student_answer.strip().lower() == correct_answer.strip().lower()\n",
    "            \n",
    "            if is_correct:\n",
    "                feedback = \"Excellent! Your answer is correct.\"\n",
    "            else:\n",
    "                feedback = f\"Not quite. Let's review the solution step by step.\"\n",
    "            \n",
    "            return {\n",
    "                \"is_correct\": is_correct,\n",
    "                \"feedback\": feedback,\n",
    "                \"student_answer\": student_answer,\n",
    "                \"correct_answer\": correct_answer\n",
    "            }\n",
    "        \n",
    "        @tool(registry=registry)\n",
    "        def generate_lesson_plan(student_id: str, subject: str, duration: int) -> str:\n",
    "            \"\"\"Generate personalized lesson plan.\"\"\"\n",
    "            profile = self.student_profiles.get(student_id, {})\n",
    "            \n",
    "            prompt = f\"\"\"Create a {duration}-minute lesson plan for {subject}.\n",
    "Student level: {profile.get('level', 'intermediate')}\n",
    "Learning style: {profile.get('learning_style', 'visual')}\n",
    "\n",
    "Include: objectives, activities, practice problems, and assessment.\"\"\"\n",
    "            \n",
    "            return self.client.complete(prompt)\n",
    "        \n",
    "        @tool(registry=registry)\n",
    "        def track_progress(student_id: str, lesson_data: dict) -> dict:\n",
    "            \"\"\"Track student progress.\"\"\"\n",
    "            if student_id not in self.lesson_history:\n",
    "                self.lesson_history[student_id] = []\n",
    "            \n",
    "            self.lesson_history[student_id].append({\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                **lesson_data\n",
    "            })\n",
    "            \n",
    "            # Calculate progress metrics\n",
    "            total_lessons = len(self.lesson_history[student_id])\n",
    "            correct_answers = sum(\n",
    "                1 for lesson in self.lesson_history[student_id]\n",
    "                if lesson.get('score', 0) > 0.7\n",
    "            )\n",
    "            \n",
    "            return {\n",
    "                \"total_lessons\": total_lessons,\n",
    "                \"success_rate\": correct_answers / max(total_lessons, 1),\n",
    "                \"streak\": self._calculate_streak(student_id)\n",
    "            }\n",
    "        \n",
    "        return registry\n",
    "    \n",
    "    def _calculate_streak(self, student_id: str) -> int:\n",
    "        \"\"\"Calculate learning streak.\"\"\"\n",
    "        if student_id not in self.lesson_history:\n",
    "            return 0\n",
    "        \n",
    "        # Simplified streak calculation\n",
    "        return min(len(self.lesson_history[student_id]), 7)\n",
    "    \n",
    "    def create_student(self, student_id: str, name: str, grade: int, learning_style: str):\n",
    "        \"\"\"Create a new student profile.\"\"\"\n",
    "        self.student_profiles[student_id] = {\n",
    "            \"name\": name,\n",
    "            \"grade\": grade,\n",
    "            \"learning_style\": learning_style,\n",
    "            \"level\": \"beginner\",\n",
    "            \"subjects\": [],\n",
    "            \"created_at\": datetime.now().isoformat()\n",
    "        }\n",
    "    \n",
    "    def tutor_session(self, student_id: str, request: str) -> str:\n",
    "        \"\"\"Conduct a tutoring session.\"\"\"\n",
    "        # Add context about the student\n",
    "        context = f\"\"\"You are tutoring student {student_id}.\n",
    "Student profile: {json.dumps(self.student_profiles.get(student_id, {}))}\n",
    "\n",
    "Student request: {request}\"\"\"\n",
    "        \n",
    "        return self.tutor_agent.run(context)\n",
    "\n",
    "# Test the Tutoring System\n",
    "tutor_system = AITutoringSystem(client)\n",
    "\n",
    "# Create student profiles\n",
    "tutor_system.create_student(\"alice123\", \"Alice\", 10, \"visual\")\n",
    "tutor_system.create_student(\"bob456\", \"Bob\", 12, \"kinesthetic\")\n",
    "\n",
    "print(\"AI Tutoring System Demo\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Tutoring sessions\n",
    "sessions = [\n",
    "    (\"alice123\", \"I need help with solving equations\"),\n",
    "    (\"alice123\", \"Can you give me a practice problem about algebra?\"),\n",
    "    (\"bob456\", \"Explain what derivatives are in calculus\"),\n",
    "    (\"bob456\", \"Create a 30-minute lesson plan for me on Python basics\")\n",
    "]\n",
    "\n",
    "for student_id, request in sessions:\n",
    "    print(f\"\\nStudent: {student_id}\")\n",
    "    print(f\"Request: {request}\")\n",
    "    print(\"-\" * 30)\n",
    "    response = tutor_system.tutor_session(student_id, request)\n",
    "    print(f\"Tutor Response: {response[:300]}...\")\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Research Assistant\n",
    "\n",
    "An AI research assistant that helps with literature review and analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchAssistant:\n",
    "    \"\"\"AI-powered research assistant.\"\"\"\n",
    "    \n",
    "    def __init__(self, client):\n",
    "        self.client = client\n",
    "        self.papers = {}\n",
    "        self.research_notes = {}\n",
    "        self.tools = self._create_tools()\n",
    "        self.agent = Agent(llm=client, tools=self.tools, max_steps=12)\n",
    "    \n",
    "    def _create_tools(self) -> ToolRegistry:\n",
    "        registry = ToolRegistry()\n",
    "        \n",
    "        @tool(registry=registry)\n",
    "        def search_papers(query: str, field: str = \"all\") -> list:\n",
    "            \"\"\"Search for research papers.\"\"\"\n",
    "            # Mock paper search\n",
    "            papers = [\n",
    "                {\n",
    "                    \"id\": \"paper1\",\n",
    "                    \"title\": \"Deep Learning for Natural Language Processing\",\n",
    "                    \"authors\": [\"Smith, J.\", \"Doe, A.\"],\n",
    "                    \"year\": 2023,\n",
    "                    \"abstract\": \"This paper explores deep learning techniques...\",\n",
    "                    \"field\": \"AI\"\n",
    "                },\n",
    "                {\n",
    "                    \"id\": \"paper2\",\n",
    "                    \"title\": \"Advances in Transformer Architecture\",\n",
    "                    \"authors\": [\"Johnson, B.\", \"Lee, C.\"],\n",
    "                    \"year\": 2024,\n",
    "                    \"abstract\": \"We present improvements to transformer models...\",\n",
    "                    \"field\": \"AI\"\n",
    "                }\n",
    "            ]\n",
    "            \n",
    "            # Filter by query\n",
    "            results = []\n",
    "            for paper in papers:\n",
    "                if query.lower() in paper['title'].lower() or query.lower() in paper['abstract'].lower():\n",
    "                    results.append(paper)\n",
    "            \n",
    "            return results\n",
    "        \n",
    "        @tool(registry=registry)\n",
    "        def analyze_paper(paper_id: str) -> dict:\n",
    "            \"\"\"Analyze a research paper in detail.\"\"\"\n",
    "            if paper_id not in self.papers:\n",
    "                return {\"error\": \"Paper not found\"}\n",
    "            \n",
    "            paper = self.papers[paper_id]\n",
    "            \n",
    "            analysis_prompt = f\"\"\"Analyze this research paper:\n",
    "Title: {paper['title']}\n",
    "Abstract: {paper['abstract']}\n",
    "\n",
    "Provide:\n",
    "1. Key contributions\n",
    "2. Methodology\n",
    "3. Strengths and weaknesses\n",
    "4. Potential applications\"\"\"\n",
    "            \n",
    "            analysis = self.client.complete(analysis_prompt)\n",
    "            \n",
    "            return {\n",
    "                \"paper_id\": paper_id,\n",
    "                \"analysis\": analysis,\n",
    "                \"keywords\": self._extract_keywords(paper),\n",
    "                \"citations_needed\": [\"Previous work\", \"Methodology references\"]\n",
    "            }\n",
    "        \n",
    "        @tool(registry=registry)\n",
    "        def generate_literature_review(topic: str, paper_ids: list) -> str:\n",
    "            \"\"\"Generate a literature review from selected papers.\"\"\"\n",
    "            papers_info = []\n",
    "            for paper_id in paper_ids:\n",
    "                if paper_id in self.papers:\n",
    "                    papers_info.append(self.papers[paper_id])\n",
    "            \n",
    "            if not papers_info:\n",
    "                return \"No papers found for review\"\n",
    "            \n",
    "            review_prompt = f\"\"\"Write a literature review on '{topic}' based on these papers:\n",
    "\n",
    "{json.dumps(papers_info, indent=2)}\n",
    "\n",
    "Include:\n",
    "- Introduction to the field\n",
    "- Summary of each paper's contributions\n",
    "- Synthesis of findings\n",
    "- Gaps in current research\n",
    "- Future directions\"\"\"\n",
    "            \n",
    "            return self.client.complete(review_prompt)\n",
    "        \n",
    "        @tool(registry=registry)\n",
    "        def extract_methodology(paper_id: str) -> dict:\n",
    "            \"\"\"Extract methodology details from a paper.\"\"\"\n",
    "            if paper_id not in self.papers:\n",
    "                return {\"error\": \"Paper not found\"}\n",
    "            \n",
    "            # Mock methodology extraction\n",
    "            return {\n",
    "                \"approach\": \"Deep learning\",\n",
    "                \"dataset\": \"Custom dataset with 10k samples\",\n",
    "                \"evaluation_metrics\": [\"accuracy\", \"F1-score\", \"precision\", \"recall\"],\n",
    "                \"implementation\": \"PyTorch\",\n",
    "                \"hardware\": \"NVIDIA A100 GPU\"\n",
    "            }\n",
    "        \n",
    "        @tool(registry=registry)\n",
    "        def create_research_note(title: str, content: str, paper_refs: list) -> dict:\n",
    "            \"\"\"Create a research note with references.\"\"\"\n",
    "            note_id = f\"note_{len(self.research_notes) + 1}\"\n",
    "            \n",
    "            self.research_notes[note_id] = {\n",
    "                \"id\": note_id,\n",
    "                \"title\": title,\n",
    "                \"content\": content,\n",
    "                \"paper_refs\": paper_refs,\n",
    "                \"created_at\": datetime.now().isoformat()\n",
    "            }\n",
    "            \n",
    "            return {\"note_id\": note_id, \"status\": \"created\"}\n",
    "        \n",
    "        @tool(registry=registry)\n",
    "        def suggest_related_work(paper_id: str) -> list:\n",
    "            \"\"\"Suggest related papers.\"\"\"\n",
    "            # Mock suggestions\n",
    "            return [\n",
    "                {\n",
    "                    \"title\": \"Related Work on Transformers\",\n",
    "                    \"relevance\": \"High\",\n",
    "                    \"reason\": \"Builds on similar architecture\"\n",
    "                },\n",
    "                {\n",
    "                    \"title\": \"Applications in NLP\",\n",
    "                    \"relevance\": \"Medium\",\n",
    "                    \"reason\": \"Uses similar techniques\"\n",
    "                }\n",
    "            ]\n",
    "        \n",
    "        return registry\n",
    "    \n",
    "    def _extract_keywords(self, paper: dict) -> list:\n",
    "        \"\"\"Extract keywords from paper.\"\"\"\n",
    "        # Simplified keyword extraction\n",
    "        text = f\"{paper['title']} {paper['abstract']}\"\n",
    "        # Mock keywords\n",
    "        return [\"deep learning\", \"NLP\", \"transformers\", \"neural networks\"]\n",
    "    \n",
    "    def add_paper(self, paper_id: str, title: str, authors: list, year: int, abstract: str):\n",
    "        \"\"\"Add a paper to the system.\"\"\"\n",
    "        self.papers[paper_id] = {\n",
    "            \"id\": paper_id,\n",
    "            \"title\": title,\n",
    "            \"authors\": authors,\n",
    "            \"year\": year,\n",
    "            \"abstract\": abstract,\n",
    "            \"added_at\": datetime.now().isoformat()\n",
    "        }\n",
    "    \n",
    "    def assist(self, query: str) -> str:\n",
    "        \"\"\"Assist with research query.\"\"\"\n",
    "        return self.agent.run(query)\n",
    "\n",
    "# Test the Research Assistant\n",
    "research_assistant = ResearchAssistant(client)\n",
    "\n",
    "# Add sample papers\n",
    "research_assistant.add_paper(\n",
    "    \"paper1\",\n",
    "    \"Attention Is All You Need\",\n",
    "    [\"Vaswani, A.\", \"et al.\"],\n",
    "    2017,\n",
    "    \"We propose a new simple network architecture, the Transformer, based solely on attention mechanisms.\"\n",
    ")\n",
    "\n",
    "research_assistant.add_paper(\n",
    "    \"paper2\",\n",
    "    \"BERT: Pre-training of Deep Bidirectional Transformers\",\n",
    "    [\"Devlin, J.\", \"et al.\"],\n",
    "    2018,\n",
    "    \"We introduce a new language representation model called BERT.\"\n",
    ")\n",
    "\n",
    "research_assistant.add_paper(\n",
    "    \"paper3\",\n",
    "    \"GPT-3: Language Models are Few-Shot Learners\",\n",
    "    [\"Brown, T.\", \"et al.\"],\n",
    "    2020,\n",
    "    \"We demonstrate that scaling up language models greatly improves task-agnostic, few-shot performance.\"\n",
    ")\n",
    "\n",
    "print(\"Research Assistant Demo\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test queries\n",
    "queries = [\n",
    "    \"Search for papers about transformers\",\n",
    "    \"Analyze the paper about BERT\",\n",
    "    \"Generate a literature review on transformer-based language models using papers paper1, paper2, and paper3\",\n",
    "    \"What methodology was used in the attention paper?\",\n",
    "    \"Create a research note about the evolution of language models\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    print(\"-\" * 30)\n",
    "    response = research_assistant.assist(query)\n",
    "    print(f\"Response: {response[:400]}...\")\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Content Generation Pipeline\n",
    "\n",
    "A complete content generation system for blogs and articles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentGenerationPipeline:\n",
    "    \"\"\"AI-powered content generation system.\"\"\"\n",
    "    \n",
    "    def __init__(self, client):\n",
    "        self.client = client\n",
    "        self.content_templates = self._create_templates()\n",
    "        self.seo_keywords = {}\n",
    "        self.generated_content = {}\n",
    "    \n",
    "    def _create_templates(self) -> dict:\n",
    "        \"\"\"Create content templates.\"\"\"\n",
    "        return {\n",
    "            \"blog_post\": PromptTemplate(\n",
    "                \"\"\"Write a {word_count}-word blog post about {topic}.\n",
    "                \n",
    "Target audience: {audience}\n",
    "Tone: {tone}\n",
    "Keywords to include: {keywords}\n",
    "\n",
    "Structure:\n",
    "- Engaging introduction\n",
    "- {num_sections} main sections with subheadings\n",
    "- Actionable takeaways\n",
    "- Compelling conclusion\"\"\",\n",
    "                word_count=800,\n",
    "                tone=\"professional yet conversational\",\n",
    "                num_sections=3\n",
    "            ),\n",
    "            \n",
    "            \"social_media\": PromptTemplate(\n",
    "                \"\"\"Create {platform} posts about {topic}.\n",
    "                \n",
    "Brand voice: {brand_voice}\n",
    "Include: {hashtags} relevant hashtags\n",
    "Call-to-action: {cta}\n",
    "\n",
    "Generate {num_posts} variations.\"\"\",\n",
    "                platform=\"LinkedIn\",\n",
    "                hashtags=5,\n",
    "                num_posts=3\n",
    "            ),\n",
    "            \n",
    "            \"email_newsletter\": PromptTemplate(\n",
    "                \"\"\"Write an email newsletter about {topic}.\n",
    "                \n",
    "Subject line options: 3\n",
    "Preview text: Yes\n",
    "Sections: {sections}\n",
    "Tone: {tone}\n",
    "CTA: {cta}\"\"\",\n",
    "                tone=\"friendly and informative\"\n",
    "            )\n",
    "        }\n",
    "    \n",
    "    def generate_content(self, content_type: str, **params) -> dict:\n",
    "        \"\"\"Generate content using the pipeline.\"\"\"\n",
    "        pipeline = Chain()\n",
    "        \n",
    "        # Step 1: Research\n",
    "        pipeline.add_step(\n",
    "            \"research\",\n",
    "            lambda: self._research_topic(params.get('topic', ''))\n",
    "        )\n",
    "        \n",
    "        # Step 2: Generate outline\n",
    "        pipeline.add_step(\n",
    "            \"outline\",\n",
    "            lambda research: self._generate_outline(\n",
    "                content_type, research, **params\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Step 3: Create content\n",
    "        pipeline.add_step(\n",
    "            \"create\",\n",
    "            lambda outline: self._create_content(\n",
    "                content_type, outline, **params\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Step 4: Optimize\n",
    "        pipeline.add_step(\n",
    "            \"optimize\",\n",
    "            lambda content: self._optimize_content(content, **params)\n",
    "        )\n",
    "        \n",
    "        # Step 5: Format\n",
    "        pipeline.add_step(\n",
    "            \"format\",\n",
    "            lambda optimized: self._format_content(\n",
    "                content_type, optimized\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        result = pipeline.run()\n",
    "        \n",
    "        # Store generated content\n",
    "        content_id = f\"{content_type}_{len(self.generated_content) + 1}\"\n",
    "        self.generated_content[content_id] = {\n",
    "            \"id\": content_id,\n",
    "            \"type\": content_type,\n",
    "            \"params\": params,\n",
    "            \"content\": result,\n",
    "            \"created_at\": datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            \"content_id\": content_id,\n",
    "            \"content\": result,\n",
    "            \"metrics\": self._calculate_metrics(result)\n",
    "        }\n",
    "    \n",
    "    def _research_topic(self, topic: str) -> dict:\n",
    "        \"\"\"Research the topic.\"\"\"\n",
    "        research_prompt = f\"\"\"Research the topic '{topic}' and provide:\n",
    "1. Key points to cover\n",
    "2. Current trends\n",
    "3. Common questions\n",
    "4. Expert insights\"\"\"\n",
    "        \n",
    "        research = self.client.complete(research_prompt)\n",
    "        \n",
    "        # Extract keywords for SEO\n",
    "        keywords = self._extract_seo_keywords(topic, research)\n",
    "        self.seo_keywords[topic] = keywords\n",
    "        \n",
    "        return {\n",
    "            \"topic\": topic,\n",
    "            \"research\": research,\n",
    "            \"keywords\": keywords\n",
    "        }\n",
    "    \n",
    "    def _extract_seo_keywords(self, topic: str, research: str) -> list:\n",
    "        \"\"\"Extract SEO keywords.\"\"\"\n",
    "        keyword_prompt = f\"\"\"Extract 10 SEO keywords from this topic and research:\n",
    "Topic: {topic}\n",
    "Research: {research[:500]}...\n",
    "\n",
    "Return as a comma-separated list.\"\"\"\n",
    "        \n",
    "        keywords = self.client.complete(keyword_prompt)\n",
    "        return [k.strip() for k in keywords.split(',')][:10]\n",
    "    \n",
    "    def _generate_outline(self, content_type: str, research: dict, **params) -> dict:\n",
    "        \"\"\"Generate content outline.\"\"\"\n",
    "        outline_prompt = f\"\"\"Create a detailed outline for a {content_type} about '{research['topic']}'.\n",
    "        \n",
    "Research insights: {research['research'][:500]}...\n",
    "Target audience: {params.get('audience', 'general')}\n",
    "\n",
    "Include section titles, key points, and suggested examples.\"\"\"\n",
    "        \n",
    "        outline = self.client.complete(outline_prompt)\n",
    "        \n",
    "        return {\n",
    "            \"outline\": outline,\n",
    "            \"research\": research\n",
    "        }\n",
    "    \n",
    "    def _create_content(self, content_type: str, outline_data: dict, **params) -> str:\n",
    "        \"\"\"Create the actual content.\"\"\"\n",
    "        template = self.content_templates.get(content_type)\n",
    "        \n",
    "        if template:\n",
    "            # Format template with params\n",
    "            content_prompt = template.format(\n",
    "                topic=params.get('topic'),\n",
    "                keywords=', '.join(outline_data['research']['keywords']),\n",
    "                **params\n",
    "            )\n",
    "        else:\n",
    "            content_prompt = f\"Create {content_type} content based on: {outline_data['outline']}\"\n",
    "        \n",
    "        return self.client.complete(content_prompt)\n",
    "    \n",
    "    def _optimize_content(self, content: str, **params) -> str:\n",
    "        \"\"\"Optimize content for SEO and readability.\"\"\"\n",
    "        optimization_prompt = f\"\"\"Optimize this content:\n",
    "{content[:1000]}...\n",
    "\n",
    "Optimization goals:\n",
    "1. Include keywords naturally: {', '.join(self.seo_keywords.get(params.get('topic', ''), []))}\n",
    "2. Improve readability (shorter sentences, active voice)\n",
    "3. Add internal structure (subheadings, bullet points)\n",
    "4. Ensure compelling opening and closing\"\"\"\n",
    "        \n",
    "        return self.client.complete(optimization_prompt)\n",
    "    \n",
    "    def _format_content(self, content_type: str, content: str) -> dict:\n",
    "        \"\"\"Format content for publication.\"\"\"\n",
    "        formatted = {\n",
    "            \"content\": content,\n",
    "            \"metadata\": {\n",
    "                \"type\": content_type,\n",
    "                \"word_count\": len(content.split()),\n",
    "                \"reading_time\": len(content.split()) // 200  # Avg reading speed\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Add type-specific formatting\n",
    "        if content_type == \"blog_post\":\n",
    "            formatted[\"seo\"] = {\n",
    "                \"meta_description\": self._generate_meta_description(content),\n",
    "                \"slug\": self._generate_slug(content)\n",
    "            }\n",
    "        \n",
    "        return formatted\n",
    "    \n",
    "    def _generate_meta_description(self, content: str) -> str:\n",
    "        \"\"\"Generate SEO meta description.\"\"\"\n",
    "        prompt = f\"Write a 150-character meta description for: {content[:200]}...\"\n",
    "        return self.client.complete(prompt)\n",
    "    \n",
    "    def _generate_slug(self, content: str) -> str:\n",
    "        \"\"\"Generate URL slug.\"\"\"\n",
    "        # Extract title from content (simplified)\n",
    "        lines = content.split('\\n')\n",
    "        title = lines[0] if lines else \"untitled\"\n",
    "        \n",
    "        # Convert to slug\n",
    "        slug = re.sub(r'[^a-z0-9]+', '-', title.lower())\n",
    "        return slug.strip('-')\n",
    "    \n",
    "    def _calculate_metrics(self, content: dict) -> dict:\n",
    "        \"\"\"Calculate content metrics.\"\"\"\n",
    "        text = content.get('content', '')\n",
    "        \n",
    "        return {\n",
    "            \"word_count\": len(text.split()),\n",
    "            \"sentence_count\": len(re.split(r'[.!?]+', text)),\n",
    "            \"paragraph_count\": len(text.split('\\n\\n')),\n",
    "            \"reading_time_minutes\": len(text.split()) // 200,\n",
    "            \"seo_score\": self._calculate_seo_score(text)\n",
    "        }\n",
    "    \n",
    "    def _calculate_seo_score(self, text: str) -> int:\n",
    "        \"\"\"Calculate basic SEO score.\"\"\"\n",
    "        score = 50  # Base score\n",
    "        \n",
    "        # Check for keywords\n",
    "        if any(kw in text.lower() for kw in ['ai', 'technology', 'innovation']):\n",
    "            score += 20\n",
    "        \n",
    "        # Check structure\n",
    "        if '##' in text or 'h2' in text.lower():\n",
    "            score += 15\n",
    "        \n",
    "        # Check length\n",
    "        if 300 <= len(text.split()) <= 2000:\n",
    "            score += 15\n",
    "        \n",
    "        return min(score, 100)\n",
    "\n",
    "# Test the Content Generation Pipeline\n",
    "content_pipeline = ContentGenerationPipeline(client)\n",
    "\n",
    "print(\"Content Generation Pipeline Demo\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Generate different types of content\n",
    "content_requests = [\n",
    "    {\n",
    "        \"type\": \"blog_post\",\n",
    "        \"params\": {\n",
    "            \"topic\": \"The Future of AI in Healthcare\",\n",
    "            \"audience\": \"healthcare professionals\",\n",
    "            \"word_count\": 1000,\n",
    "            \"tone\": \"informative and optimistic\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"social_media\",\n",
    "        \"params\": {\n",
    "            \"topic\": \"AI Ethics\",\n",
    "            \"platform\": \"Twitter\",\n",
    "            \"brand_voice\": \"thought leader\",\n",
    "            \"cta\": \"Join the discussion\",\n",
    "            \"num_posts\": 3\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"email_newsletter\",\n",
    "        \"params\": {\n",
    "            \"topic\": \"Monthly AI Innovations\",\n",
    "            \"sections\": \"news, tutorials, resources\",\n",
    "            \"cta\": \"Subscribe for more insights\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "for request in content_requests:\n",
    "    print(f\"\\nGenerating {request['type']} about '{request['params']['topic']}'\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    result = content_pipeline.generate_content(\n",
    "        request['type'],\n",
    "        **request['params']\n",
    "    )\n",
    "    \n",
    "    print(f\"Content ID: {result['content_id']}\")\n",
    "    print(f\"Preview: {str(result['content'])[:300]}...\")\n",
    "    print(f\"Metrics: {result['metrics']}\")\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, you've seen complete, production-ready applications:\n",
    "\n",
    "- âœ… **Document Intelligence System** - Analyze and query documents\n",
    "- âœ… **AI Tutoring System** - Personalized education assistant\n",
    "- âœ… **Research Assistant** - Literature review and analysis\n",
    "- âœ… **Content Generation Pipeline** - Automated content creation\n",
    "\n",
    "These examples demonstrate:\n",
    "- Complex agent systems with multiple tools\n",
    "- Chain-based workflows\n",
    "- Session and state management\n",
    "- Real-world integration patterns\n",
    "- Production-ready error handling\n",
    "\n",
    "## What You've Learned\n",
    "\n",
    "Throughout all tutorials, you've mastered:\n",
    "\n",
    "1. **Core Concepts**: LLM clients, prompts, sessions\n",
    "2. **Building Blocks**: Templates, chains, tools\n",
    "3. **Advanced Features**: Agents, async operations, streaming\n",
    "4. **Real Applications**: Complete systems ready for production\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Now you're ready to:\n",
    "- Build your own AI-powered applications\n",
    "- Extend AILib with custom features\n",
    "- Deploy agents in production\n",
    "- Create innovative AI solutions\n",
    "\n",
    "Happy building with AILib! ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
