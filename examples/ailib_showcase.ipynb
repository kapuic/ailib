{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AILib: Comprehensive Feature Showcase\n",
    "\n",
    "This notebook demonstrates all the features of AILib, a simple and intuitive Python SDK for building LLM-powered applications.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Setup and Installation](#setup)\n",
    "2. [Basic LLM Completions](#basic-completions)\n",
    "3. [Prompt Templates](#prompt-templates)\n",
    "4. [Building Conversations with Prompt Builder](#prompt-builder)\n",
    "5. [Session Management](#session-management)\n",
    "6. [Chains: Sequential Operations](#chains)\n",
    "7. [Tools and Decorators](#tools)\n",
    "8. [Agents: Autonomous Problem Solving](#agents)\n",
    "9. [Advanced Features](#advanced)\n",
    "10. [Real-World Examples](#examples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation <a id='setup'></a>\n",
    "\n",
    "First, let's set up the environment and import the necessary modules.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install AILib (if not already installed)\n",
    "# !pip install -e ..\n",
    "\n",
    "# Set up environment variable for OpenAI API key\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AILib imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import all AILib modules\n",
    "from ailib import (\n",
    "    # Core components\n",
    "    OpenAIClient,\n",
    "    Message,\n",
    "    Role,\n",
    "    Prompt,\n",
    "    PromptTemplate,\n",
    "    Session,\n",
    "    # Chains\n",
    "    Chain,\n",
    "    # Agents and tools\n",
    "    Agent,\n",
    "    Tool,\n",
    "    ToolRegistry,\n",
    "    tool,\n",
    ")\n",
    "\n",
    "# Import helpers\n",
    "from ailib.core.prompt import create_react_prompt, create_few_shot_prompt\n",
    "\n",
    "print(\"AILib imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic LLM Completions <a id='basic-completions'></a>\n",
    "\n",
    "Let's start with the simplest use case: getting a completion from an LLM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The capital of France is Paris.\n",
      "\n",
      "Model used: gpt-3.5-turbo-0125\n",
      "Tokens used: {'prompt_tokens': 24, 'completion_tokens': 7, 'total_tokens': 31}\n"
     ]
    }
   ],
   "source": [
    "# Initialize the OpenAI client\n",
    "client = OpenAIClient(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Create a simple message\n",
    "messages = [\n",
    "    Message(role=Role.SYSTEM, content=\"You are a helpful assistant.\"),\n",
    "    Message(role=Role.USER, content=\"What is the capital of France?\"),\n",
    "]\n",
    "\n",
    "# Get completion\n",
    "response = client.complete(messages)\n",
    "\n",
    "print(f\"Response: {response.content}\")\n",
    "print(f\"\\nModel used: {response.model}\")\n",
    "print(f\"Tokens used: {response.usage}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Responses\n",
    "\n",
    "AILib supports streaming for real-time output:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming response:\n",
      "Infinite loops spin\n",
      "Code dances across the screen\n",
      "Solving problems, one\n",
      "\n",
      "Streaming complete!\n"
     ]
    }
   ],
   "source": [
    "# Stream a response token by token\n",
    "messages = [Message(role=Role.USER, content=\"Write a haiku about programming\")]\n",
    "\n",
    "print(\"Streaming response:\")\n",
    "for token in client.stream(messages):\n",
    "    print(token, end=\"\", flush=True)\n",
    "print(\"\\n\\nStreaming complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prompt Templates <a id='prompt-templates'></a>\n",
    "\n",
    "Prompt templates allow you to create reusable prompts with variable substitution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template variables: ['target_lang', 'source_lang', 'text']\n",
      "\n",
      "Formatted prompt: Translate the following English text to French: 'Hello, world!'\n"
     ]
    }
   ],
   "source": [
    "# Create a simple template\n",
    "template = PromptTemplate(\n",
    "    \"Translate the following {source_lang} text to {target_lang}: '{text}'\"\n",
    ")\n",
    "\n",
    "# Show template variables\n",
    "print(f\"Template variables: {template.variables}\")\n",
    "\n",
    "# Format the template\n",
    "formatted = template.format(\n",
    "    source_lang=\"English\", target_lang=\"French\", text=\"Hello, world!\"\n",
    ")\n",
    "print(f\"\\nFormatted prompt: {formatted}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial Templates\n",
    "\n",
    "You can create partial templates by pre-filling some variables:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining variables: ['source_lang', 'text']\n",
      "Translate the following English text to Spanish: 'Good morning'\n",
      "Translate the following French text to Spanish: 'Bonjour'\n"
     ]
    }
   ],
   "source": [
    "# Create a partial template with target language pre-filled\n",
    "spanish_translator = template.partial(target_lang=\"Spanish\")\n",
    "\n",
    "print(f\"Remaining variables: {spanish_translator.variables}\")\n",
    "\n",
    "# Use the partial template\n",
    "translations = [\n",
    "    spanish_translator.format(source_lang=\"English\", text=\"Good morning\"),\n",
    "    spanish_translator.format(source_lang=\"French\", text=\"Bonjour\"),\n",
    "]\n",
    "\n",
    "for prompt in translations:\n",
    "    print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Templates with LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: \u00bfC\u00f3mo est\u00e1s?\n"
     ]
    }
   ],
   "source": [
    "# Create a message from template and get completion\n",
    "message = spanish_translator.create_message(source_lang=\"English\", text=\"How are you?\")\n",
    "\n",
    "response = client.complete([message])\n",
    "print(f\"Translation: {response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Building Conversations with Prompt Builder <a id='prompt-builder'></a>\n",
    "\n",
    "The Prompt builder provides a fluent API for constructing multi-message conversations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. [system]: You are a Python programming tutor....\n",
      "2. [user]: What is a list comprehension?...\n",
      "3. [assistant]: A list comprehension is a concise way to create li...\n",
      "4. [user]: Can you show me an example?...\n"
     ]
    }
   ],
   "source": [
    "# Build a conversation using the fluent API\n",
    "prompt = Prompt()\n",
    "prompt.add_system(\"You are a Python programming tutor.\")\n",
    "prompt.add_user(\"What is a list comprehension?\")\n",
    "prompt.add_assistant(\n",
    "    \"A list comprehension is a concise way to create lists in Python...\"\n",
    ")\n",
    "prompt.add_user(\"Can you show me an example?\")\n",
    "\n",
    "# Get the messages\n",
    "messages = prompt.build()\n",
    "\n",
    "# Display the conversation\n",
    "for i, msg in enumerate(messages):\n",
    "    print(f\"{i+1}. [{msg.role.value}]: {msg.content[:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Templates in Conversations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code Review:\n",
      "This code looks concise and functional, but it could be improved for better readability and maintainability. Here are some suggestions:\n",
      "\n",
      "1. **Whitespace**: Add whitespace around the `:` and `,` for better readability:\n",
      "   ```python\n",
      "   def add(a, b): return a + b\n",
      "   ```\n",
      "\n",
      "2. **Documentation**: Add a docstring to describe the function's purpose and parameters:\n",
      "   ```python\n",
      "   def add(a, b):\n",
      "       \"\"\"Add two numbers together.\"\"\"\n",
      "       return a + b\n",
      "   ```\n",
      "\n",
      "3. **Error Handling**: Consider adding error handling for cases where `a` or `b` are not numbers.\n",
      "\n",
      "4. **Type Hints**: Consider adding type hints for the function parameters and return value for better code readability and maintainability:\n",
      "   ```python\n",
      "   def add(a: int, b: int) -> int:\n",
      "       \"\"\"Add two numbers together.\"\"\"\n",
      "       return a + b\n",
      "   ```\n",
      "\n",
      "5. **Pep8**: Ensure the code follows the PEP8 style guide for Python to maintain consistency.\n",
      "\n",
      "Overall, the code is functional but could benefit from some enhancements for better readability and maintainability.\n"
     ]
    }
   ],
   "source": [
    "# Build a conversation with templates\n",
    "code_review_prompt = Prompt()\n",
    "code_review_prompt.add_system(\"You are a code reviewer specializing in {language}.\")\n",
    "code_review_prompt.add_template(\n",
    "    \"Review this {language} code for best practices:\\n```{language}\\n{code}\\n```\",\n",
    "    role=Role.USER,\n",
    "    language=\"Python\",\n",
    "    code=\"def add(a,b): return a+b\",\n",
    ")\n",
    "\n",
    "# Get completion\n",
    "messages = code_review_prompt.build()\n",
    "response = client.complete(messages)\n",
    "print(\"Code Review:\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Session Management <a id='session-management'></a>\n",
    "\n",
    "Sessions help maintain conversation state and memory across interactions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session ID: ac3e282d-ad52-4d45-8345-31bf9eb0636a\n",
      "Created at: 2025-07-29 07:50:58.632250\n"
     ]
    }
   ],
   "source": [
    "# Create a new session\n",
    "session = Session()\n",
    "\n",
    "print(f\"Session ID: {session.session_id}\")\n",
    "print(f\"Created at: {session.created_at}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Managing Conversation History\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First interaction:\n",
      "The Pythagorean theorem states that in a right-angled triangle, the square of the length of the hypotenuse (the side opposite the right angle) is equal to the sum of the squares of the lengths of the ...\n",
      "\n",
      "Second interaction (with context):\n",
      "Sure! Let's consider a right-angled triangle with side lengths of 3 units, 4 units, and an unknown length for the hypotenuse (denoted as \\( c \\)).\n",
      "\n",
      "Using the Pythagorean theorem, we have:\n",
      "\n",
      "\\( 3^2 + 4^...\n",
      "\n",
      "Total messages in session: 5\n"
     ]
    }
   ],
   "source": [
    "# Add messages to session\n",
    "session.add_system_message(\"You are a helpful math tutor.\")\n",
    "session.add_user_message(\"What is the Pythagorean theorem?\")\n",
    "\n",
    "# Get response from LLM\n",
    "response = client.complete(session.get_messages())\n",
    "session.add_assistant_message(response.content)\n",
    "\n",
    "print(\"First interaction:\")\n",
    "print(response.content[:200] + \"...\")\n",
    "\n",
    "# Continue the conversation\n",
    "session.add_user_message(\"Can you give me an example with numbers?\")\n",
    "response = client.complete(session.get_messages())\n",
    "session.add_assistant_message(response.content)\n",
    "\n",
    "print(\"\\nSecond interaction (with context):\")\n",
    "print(response.content[:200] + \"...\")\n",
    "\n",
    "print(f\"\\nTotal messages in session: {len(session)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session Memory Storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Alice\n",
      "Topic: Pythagorean theorem\n",
      "Level: beginner\n",
      "\n",
      "All memory: {'user_name': 'Alice', 'topic': 'Pythagorean theorem', 'skill_level': 'beginner', 'examples_given': 2, 'last_question': 'Pythagorean theorem example'}\n"
     ]
    }
   ],
   "source": [
    "# Store information in session memory\n",
    "session.set_memory(\"user_name\", \"Alice\")\n",
    "session.set_memory(\"topic\", \"Pythagorean theorem\")\n",
    "session.set_memory(\"skill_level\", \"beginner\")\n",
    "\n",
    "# Retrieve memory\n",
    "print(f\"User: {session.get_memory('user_name')}\")\n",
    "print(f\"Topic: {session.get_memory('topic')}\")\n",
    "print(f\"Level: {session.get_memory('skill_level')}\")\n",
    "\n",
    "# Update multiple values\n",
    "session.update_memory(\n",
    "    {\"examples_given\": 2, \"last_question\": \"Pythagorean theorem example\"}\n",
    ")\n",
    "\n",
    "print(f\"\\nAll memory: {session._memory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session Persistence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session data keys: ['session_id', 'created_at', 'messages', 'memory', 'metadata', 'trace']\n",
      "\n",
      "Restored session ID: ac3e282d-ad52-4d45-8345-31bf9eb0636a\n",
      "Restored messages: 5\n",
      "Restored memory: Alice\n"
     ]
    }
   ],
   "source": [
    "# Convert session to dict (for saving)\n",
    "session_data = session.to_dict()\n",
    "print(f\"Session data keys: {list(session_data.keys())}\")\n",
    "\n",
    "# Restore session from dict\n",
    "restored_session = Session.from_dict(session_data)\n",
    "print(f\"\\nRestored session ID: {restored_session.session_id}\")\n",
    "print(f\"Restored messages: {len(restored_session)}\")\n",
    "print(f\"Restored memory: {restored_session.get_memory('user_name')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Chains: Sequential Operations <a id='chains'></a>\n",
    "\n",
    "Chains allow you to execute multiple prompts sequentially, with each step building on the previous.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "# Create a simple chain\n",
    "chain = Chain(client)\n",
    "chain.add_system(\"You are a helpful assistant.\")\n",
    "chain.add_user(\"What is the capital of France?\")\n",
    "\n",
    "# Run the chain\n",
    "result = chain.run()\n",
    "print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Step Chains with Context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[step_1] Sending 1 messages...\n",
      "Last message: You are a creative storyteller....\n",
      "[step_1] Response: Once upon a time, in a faraway land called Lumina, there was a young girl named Elara who had a special gift. Elara had the ability to communicate with animals, understanding their thoughts and feelin...\n",
      "\n",
      "[character_name] Sending 3 messages...\n",
      "Last message: Generate a random character name for a fantasy story...\n",
      "[character_name] Response: Thornwyn Emberheart...\n",
      "\n",
      "[backstory] Sending 5 messages...\n",
      "Last message: Create a one-sentence backstory for Thornwyn Emberheart...\n",
      "[backstory] Response: Thornwyn Emberheart, a fierce warrior with a mysterious past, was born under the light of a blood-red moon and raised by a pack of ancient wolves in the shadow of the forbidden Blackwood Forest....\n",
      "\n",
      "[scene] Sending 7 messages...\n",
      "Last message: Write a short adventure scene featuring Thornwyn Emberheart. Their backstory: Thornwyn Emberheart, a...\n",
      "[scene] Response: Thornwyn Emberheart stood at the edge of the Blackwood Forest, the moon casting an eerie glow over the twisted trees and tangled undergrowth. As she prepared to venture into the forbidden realm that h...\n",
      "\n",
      "=== Final Scene ===\n",
      "Thornwyn Emberheart stood at the edge of the Blackwood Forest, the moon casting an eerie glow over the twisted trees and tangled undergrowth. As she prepared to venture into the forbidden realm that had once been her home, the howls of her wolf brethren echoed through the night, a haunting melody that stirred memories long buried in her heart.\n",
      "\n",
      "With a determined gleam in her eye, Thornwyn took a deep breath and stepped into the darkness, her senses keen and her instincts sharp. The forest seemed to come alive around her, shadows dancing at the edge of her vision and whispers of ancient magic stirring in the air.\n",
      "\n",
      "As she moved deeper into the heart of the Blackwood, Thornwyn felt a sense of unease creeping over her, a primal warning that danger lurked in the shadows. Suddenly, a pack of sinister shadow wolves emerged from the darkness, their eyes glowing with malevolent intent as they surrounded her, teeth bared and growls rumbling in their throats.\n",
      "\n",
      "But Thornwyn was not afraid, for she had learned the ways of the wolves and knew their language better than any other. With a low, guttural growl of her own, she communicated her challenge to the leader of the pack, a massive black wolf with eyes as cold as the winter moon.\n",
      "\n",
      "A tense silence fell over the forest as Thornwyn and the black wolf locked eyes, each daring the other to make the first move. Then, with a sudden leap, the black wolf lunged at Thornwyn, jaws snapping shut just inches from her throat.\n",
      "\n",
      "In a blur of motion, Thornwyn evaded the attack and countered with a swift strike of her own, her blade flashing in the moonlight as she engaged the shadow wolves in a fierce battle that echoed through the trees.\n",
      "\n",
      "As the last of the shadow wolves fell before her, defeated and vanquished, Thornwyn stood victorious, her chest heaving with exertion and her heart pounding with the thrill of battle. She knew that her journey was far from over, but in that moment, she felt the ancient spirits of the Blackwood Forest watching over her, whispering their approval in the wind that rustled through the trees.\n",
      "\n",
      "And so, Thornwyn Emberheart, born under the blood-red moon and raised by wolves, continued her quest through the forbidden realm, her spirit unbroken and her determination unwavering as she forged her path through darkness and light alike.\n"
     ]
    }
   ],
   "source": [
    "# Create a multi-step chain where each step uses previous results\n",
    "story_chain = (\n",
    "    Chain(client)\n",
    "    .add_system(\"You are a creative storyteller.\")\n",
    "    .add_user(\n",
    "        \"Generate a random character name for a fantasy story\", name=\"character_name\"\n",
    "    )\n",
    "    .add_user(\"Create a one-sentence backstory for {character_name}\", name=\"backstory\")\n",
    "    .add_user(\n",
    "        \"Write a short adventure scene featuring {character_name}. Their backstory: {backstory}\",\n",
    "        name=\"scene\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Enable verbose mode to see each step\n",
    "story_chain.verbose(True)\n",
    "\n",
    "# Run the chain\n",
    "final_scene = story_chain.run()\n",
    "print(\"\\n=== Final Scene ===\")\n",
    "print(final_scene)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chains with Processing Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Data:\n",
      "**Luminous Smart LED Light Bulb** - $29.99\n",
      "Transform your home with the Luminous Smart LED Light Bulb. This energy-efficient bulb can be controlled remotely via a smartphone app, allowing you to adjust brightness, color, and scheduling. With a lifespan of 25,000 hours, this smart bulb is the perfect addition to any smart home setup.\n",
      "\n",
      "Tagline: \"Illuminate Your Space, Control Your Ambiance - Experience the Future with the Luminous Smart LED Light Bulb!\"\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "# Define processor functions\n",
    "def extract_json(text: str) -> dict:\n",
    "    \"\"\"Extract JSON from LLM response.\"\"\"\n",
    "    # Find JSON in the response\n",
    "    import re\n",
    "\n",
    "    json_match = re.search(r\"\\{.*\\}\", text, re.DOTALL)\n",
    "    if json_match:\n",
    "        return json.loads(json_match.group())\n",
    "    return {}\n",
    "\n",
    "\n",
    "def format_product(data: dict) -> str:\n",
    "    \"\"\"Format product data nicely.\"\"\"\n",
    "    return f\"**{data.get('name', 'Unknown')}** - ${data.get('price', 0):.2f}\\n{data.get('description', '')}\"\n",
    "\n",
    "\n",
    "# Create a chain with processors\n",
    "product_chain = (\n",
    "    Chain(client)\n",
    "    .add_system(\"You are a product data generator.\")\n",
    "    .add_user(\n",
    "        \"Generate a random product as JSON with fields: name, price, description\",\n",
    "        processor=extract_json,\n",
    "        name=\"product_data\",\n",
    "    )\n",
    "    .add_user(\n",
    "        \"The product data is: {product_data}. Create a marketing tagline for it.\",\n",
    "        name=\"tagline\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Run the chain\n",
    "result = product_chain.run()\n",
    "\n",
    "# Access intermediate results\n",
    "print(\"Product Data:\")\n",
    "print(format_product(product_chain._context[\"product_data\"]))\n",
    "print(f\"\\nTagline: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Tools and Decorators <a id='tools'></a>\n",
    "\n",
    "Tools extend the capabilities of agents by providing functions they can call.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools registered: ['get_weather', 'web_search', 'calculate']\n"
     ]
    }
   ],
   "source": [
    "# Alternative approach: Define tools as regular functions first, then register them\n",
    "# This approach works better for re-running cells in notebooks\n",
    "\n",
    "\n",
    "def get_weather_func(city: str, unit: str = \"celsius\") -> str:\n",
    "    \"\"\"Get the current weather for a city.\"\"\"\n",
    "    import random\n",
    "\n",
    "    temp = random.randint(15, 30) if unit == \"celsius\" else random.randint(59, 86)\n",
    "    conditions = random.choice([\"sunny\", \"cloudy\", \"partly cloudy\", \"rainy\"])\n",
    "    return f\"The weather in {city} is {conditions} with a temperature of {temp}\u00b0{unit[0].upper()}\"\n",
    "\n",
    "\n",
    "def search_func(query: str, max_results: int = 3) -> str:\n",
    "    \"\"\"Perform a web search.\"\"\"\n",
    "    results = [f\"Result {i+1}: Information about {query}\" for i in range(max_results)]\n",
    "    return \"\\n\".join(results)\n",
    "\n",
    "\n",
    "def calculate_func(expression: str) -> float:\n",
    "    \"\"\"Evaluate a mathematical expression.\"\"\"\n",
    "    allowed = {\"__builtins__\": {}}\n",
    "    allowed.update(\n",
    "        {\"abs\": abs, \"round\": round, \"min\": min, \"max\": max, \"sum\": sum, \"pow\": pow}\n",
    "    )\n",
    "    try:\n",
    "        return float(eval(expression, allowed))\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "\n",
    "# Create a new registry (this clears any existing tools)\n",
    "notebook_registry = ToolRegistry()\n",
    "\n",
    "# Create tools manually\n",
    "weather_tool = Tool(\n",
    "    name=\"get_weather\", description=\"Get weather for a city\", func=get_weather_func\n",
    ")\n",
    "search_tool = Tool(name=\"web_search\", description=\"Search the web\", func=search_func)\n",
    "calc_tool = Tool(\n",
    "    name=\"calculate\", description=\"Calculate math expressions\", func=calculate_func\n",
    ")\n",
    "\n",
    "# Register tools\n",
    "notebook_registry.register(weather_tool)\n",
    "notebook_registry.register(search_tool)\n",
    "notebook_registry.register(calc_tool)\n",
    "\n",
    "print(f\"Tools registered: {notebook_registry.list_tools()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTANT: If you get \"already registered\" errors when re-running cells with @tool decorator,\n",
    "\n",
    "# restart the kernel (Kernel -> Restart) to reload the updated ailib code.\n",
    "\n",
    "# Alternatively, use the manual registration approach shown below.\n",
    "\n",
    "# Define tools using the @tool decorator with custom registry\n",
    "\n",
    "# First, let's try to clear any existing tools to allow re-running\n",
    "\n",
    "try: # If tools exist, unregister them first\n",
    "if 'notebook_registry' in globals():\n",
    "notebook_registry = ToolRegistry() # Create fresh registry\n",
    "except:\n",
    "pass\n",
    "\n",
    "# Create a fresh registry\n",
    "\n",
    "notebook_registry = ToolRegistry()\n",
    "\n",
    "@tool(registry=notebook_registry)\n",
    "def get_weather(city: str, unit: str = \"celsius\") -> str:\n",
    "\"\"\"Get the current weather for a city.\n",
    "\n",
    "    Args:\n",
    "        city: Name of the city\n",
    "        unit: Temperature unit (celsius or fahrenheit)\n",
    "    \"\"\"\n",
    "    # Mock implementation\n",
    "    import random\n",
    "\n",
    "    temp = random.randint(15, 30) if unit == \"celsius\" else random.randint(59, 86)\n",
    "    conditions = random.choice([\"sunny\", \"cloudy\", \"partly cloudy\", \"rainy\"])\n",
    "    return f\"The weather in {city} is {conditions} with a temperature of {temp}\u00b0{unit[0].upper()}\"\n",
    "\n",
    "@tool(name=\"web_search\", description=\"Search the web for information\", registry=notebook_registry)\n",
    "def search(query: str, max_results: int = 3) -> str:\n",
    "\"\"\"Perform a web search.\"\"\" # Mock implementation\n",
    "results = [f\"Result {i+1}: Information about {query}\" for i in range(max_results)]\n",
    "return \"\\n\".join(results)\n",
    "\n",
    "@tool(registry=notebook_registry)\n",
    "def calculate(expression: str) -> float:\n",
    "\"\"\"Evaluate a mathematical expression.\"\"\" # Safe evaluation\n",
    "allowed = {\"**builtins**\": {}}\n",
    "allowed.update(\n",
    "{\"abs\": abs, \"round\": round, \"min\": min, \"max\": max, \"sum\": sum, \"pow\": pow}\n",
    ")\n",
    "try:\n",
    "return float(eval(expression, allowed))\n",
    "except Exception as e:\n",
    "return f\"Error: {str(e)}\"\n",
    "\n",
    "print(\"Tools defined successfully!\")\n",
    "print(f\"Tools in registry: {notebook_registry.list_tools()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a tool manually\n",
    "\n",
    "def get_time(timezone: str = \"UTC\") -> str:\n",
    "\"\"\"Get current time in specified timezone.\"\"\"\n",
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "    try:\n",
    "        # Use zoneinfo (Python 3.9+) instead of pytz\n",
    "        tz = ZoneInfo(timezone)\n",
    "        time = datetime.now(tz)\n",
    "        return time.strftime(\"%Y-%m-%d %H:%M:%S %Z\")\n",
    "    except:\n",
    "        # Fallback to UTC\n",
    "        return datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%S UTC\")\n",
    "\n",
    "# Create Tool instance\n",
    "\n",
    "time_tool = Tool(\n",
    "name=\"get_time\", description=\"Get current time in any timezone\", func=get_time\n",
    ")\n",
    "\n",
    "# Test the tool\n",
    "\n",
    "print(\"Manual tool test:\")\n",
    "print(time_tool.execute(timezone=\"US/Pacific\"))\n",
    "print(time_tool.execute(timezone=\"UTC\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual tool test:\n",
      "2025-07-29 01:14:03 PDT\n",
      "2025-07-29 08:14:03 UTC\n"
     ]
    }
   ],
   "source": [
    "# Create a tool manually\n",
    "def get_time(timezone: str = \"UTC\") -> str:\n",
    "    \"\"\"Get current time in specified timezone.\"\"\"\n",
    "    from datetime import datetime\n",
    "\n",
    "    try:\n",
    "        # For Python 3.9+\n",
    "        from zoneinfo import ZoneInfo\n",
    "\n",
    "        tz = ZoneInfo(timezone)\n",
    "        time = datetime.now(tz)\n",
    "        return time.strftime(\"%Y-%m-%d %H:%M:%S %Z\")\n",
    "    except ImportError:\n",
    "        # Fallback for older Python versions\n",
    "        return datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%S UTC\")\n",
    "\n",
    "\n",
    "# Create Tool instance\n",
    "time_tool = Tool(\n",
    "    name=\"get_time\", description=\"Get current time in any timezone\", func=get_time\n",
    ")\n",
    "\n",
    "# Test the tool\n",
    "print(\"Manual tool test:\")\n",
    "print(time_tool.execute(timezone=\"US/Pacific\"))\n",
    "print(time_tool.execute(timezone=\"UTC\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool Registry Management\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools in registry: ['get_time', 'translate']\n",
      "\n",
      "OpenAI function format:\n",
      "- get_time: Get current time in any timezone\n",
      "- translate: Translate text to target language.\n"
     ]
    }
   ],
   "source": [
    "# Create a custom tool registry\n",
    "my_registry = ToolRegistry()\n",
    "\n",
    "# Register tools\n",
    "my_registry.register(time_tool)\n",
    "\n",
    "\n",
    "# Define and register a tool with custom registry\n",
    "@tool(registry=my_registry)\n",
    "def translate(text: str, target_language: str) -> str:\n",
    "    \"\"\"Translate text to target language.\"\"\"\n",
    "    # Mock implementation\n",
    "    translations = {\n",
    "        \"spanish\": {\"hello\": \"hola\", \"goodbye\": \"adi\u00f3s\", \"thank you\": \"gracias\"},\n",
    "        \"french\": {\"hello\": \"bonjour\", \"goodbye\": \"au revoir\", \"thank you\": \"merci\"},\n",
    "        \"german\": {\n",
    "            \"hello\": \"hallo\",\n",
    "            \"goodbye\": \"auf wiedersehen\",\n",
    "            \"thank you\": \"danke\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "    lang = target_language.lower()\n",
    "    text_lower = text.lower()\n",
    "\n",
    "    if lang in translations and text_lower in translations[lang]:\n",
    "        return translations[lang][text_lower]\n",
    "    return f\"[Translation of '{text}' to {target_language}]\"\n",
    "\n",
    "\n",
    "# List tools in registry\n",
    "print(f\"Tools in registry: {my_registry.list_tools()}\")\n",
    "\n",
    "# Get OpenAI function definitions\n",
    "functions = my_registry.to_openai_functions()\n",
    "print(f\"\\nOpenAI function format:\")\n",
    "for func in functions:\n",
    "    print(f\"- {func['name']}: {func['description']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Agents: Autonomous Problem Solving <a id='agents'></a>\n",
    "\n",
    "Agents can autonomously decide which tools to use to accomplish tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent created with 3 tools: ['get_weather', 'web_search', 'calculate']\n"
     ]
    }
   ],
   "source": [
    "# Create an agent with tools from our notebook registry\n",
    "agent = Agent(\n",
    "    llm=OpenAIClient(model=\"gpt-4\"), tools=notebook_registry, max_steps=5, verbose=True\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Agent created with {len(agent.tool_registry.list_tools())} tools: {agent.tool_registry.list_tools()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Agent Task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 1 ---\n",
      "Assistant: Thought: The user wants to know the weather in Paris. I should use the get_weather tool to find this information.\n",
      "Action: get_weather\n",
      "Action Input: {\"city\": \"Paris\"}\n",
      "\n",
      "Executing tool: get_weather\n",
      "Input: {\"city\": \"Paris\"}\n",
      "Observation: The weather in Paris is rainy with a temperature of 29\u00b0C\n",
      "\n",
      "--- Step 2 ---\n",
      "Assistant: Thought: With the information gained from the tool, I can now provide the user with the answer.\n",
      "Action: Final Answer\n",
      "Action Input: The weather in Paris is rainy with a temperature of 29\u00b0C.\n",
      "\n",
      "Final Answer: The weather in Paris is rainy with a temperature of 29\u00b0C.\n"
     ]
    }
   ],
   "source": [
    "# Run a simple task\n",
    "result = agent.run(\"What's the weather in Paris?\")\n",
    "print(f\"\\nFinal Answer: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex Multi-Tool Task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 1 ---\n",
      "Assistant: Thought: The user has asked for three different tasks. Let's start with the first one, checking the weather in Tokyo.\n",
      "\n",
      "Action: get_weather\n",
      "Action Input: {\"city\": \"Tokyo\"}\n",
      "\n",
      "Executing tool: get_weather\n",
      "Input: {\"city\": \"Tokyo\"}\n",
      "Observation: The weather in Tokyo is rainy with a temperature of 20\u00b0C\n",
      "\n",
      "--- Step 2 ---\n",
      "Assistant: Thought: Now that I have provided the weather information for Tokyo, I will proceed to the second task, which is calculating the cost of flights and hotels.\n",
      "\n",
      "Action: calculate\n",
      "Action Input: {\"expression\": \"1200 + (150 * 5)\"}\n",
      "\n",
      "Executing tool: calculate\n",
      "Input: {\"expression\": \"1200 + (150 * 5)\"}\n",
      "Observation: 1950.0\n",
      "\n",
      "--- Step 3 ---\n",
      "Assistant: Thought: Now that I have calculated the cost of flights and hotels, I will proceed to the third task, which is searching for top tourist attractions in Tokyo.\n",
      "\n",
      "Action: web_search\n",
      "Action Input: {\"query\": \"Top tourist attractions in Tokyo\"}\n",
      "\n",
      "Executing tool: web_search\n",
      "Input: {\"query\": \"Top tourist attractions in Tokyo\"}\n",
      "Observation: Result 1: Information about Top tourist attractions in Tokyo\n",
      "Result 2: Information about Top tourist attractions in Tokyo\n",
      "Result 3: Information about Top tourist attractions in Tokyo\n",
      "\n",
      "--- Step 4 ---\n",
      "Assistant: Thought: Based on the user's requests, I have gathered all the necessary information. The weather in Tokyo is rainy with a temperature of 20\u00b0C. The total cost for flights and hotels is $1950. I have also found several resources about top tourist attractions in Tokyo.\n",
      "\n",
      "Action: Final Answer\n",
      "Action Input: \"The weather in Tokyo is currently rainy with a temperature of 20\u00b0C. The total cost for flights and hotels for 5 nights would be $1950. As for the top tourist attractions in Tokyo, there are several resources available online that can provide detailed information.\"\n",
      "\n",
      "Final Answer:\n",
      "\"The weather in Tokyo is currently rainy with a temperature of 20\u00b0C. The total cost for flights and hotels for 5 nights would be $1950. As for the top tourist attractions in Tokyo, there are several resources available online that can provide detailed information.\"\n"
     ]
    }
   ],
   "source": [
    "# Run a task requiring multiple tools\n",
    "complex_task = \"\"\"\n",
    "I'm planning a trip to Tokyo. Can you:\n",
    "1. Check the weather there\n",
    "2. Calculate the cost if flights are $1200 and hotels are $150/night for 5 nights\n",
    "3. Search for top tourist attractions\n",
    "\"\"\"\n",
    "\n",
    "result = agent.run(complex_task)\n",
    "print(f\"\\nFinal Answer:\\n{result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a specialized math tutor agent with its own registry\n",
    "\n",
    "# Create a fresh registry each time to allow re-running\n",
    "\n",
    "math_registry = ToolRegistry()\n",
    "\n",
    "# Define functions first (without decorator)\n",
    "\n",
    "def solve_equation_func(equation: str) -> str:\n",
    "\"\"\"Solve algebraic equations step by step.\"\"\" # Mock implementation\n",
    "steps = [\n",
    "f\"Given: {equation}\",\n",
    "\"Step 1: Isolate the variable\",\n",
    "\"Step 2: Simplify both sides\",\n",
    "\"Step 3: Solve for x\",\n",
    "\"Solution: x = 5\",\n",
    "]\n",
    "return \"\\n\".join(steps)\n",
    "\n",
    "def explain_concept_func(concept: str) -> str:\n",
    "\"\"\"Explain a mathematical concept.\"\"\"\n",
    "explanations = {\n",
    "\"derivative\": \"The derivative measures the rate of change of a function.\",\n",
    "\"integral\": \"The integral represents the area under a curve.\",\n",
    "\"limit\": \"A limit describes the value a function approaches as input approaches a point.\",\n",
    "}\n",
    "return explanations.get(concept.lower(), f\"Explanation of {concept}...\")\n",
    "\n",
    "def math_calculate_func(expression: str) -> float:\n",
    "\"\"\"Evaluate a mathematical expression.\"\"\" # Safe evaluation\n",
    "allowed = {\"**builtins**\": {}}\n",
    "allowed.update(\n",
    "{\"abs\": abs, \"round\": round, \"min\": min, \"max\": max, \"sum\": sum, \"pow\": pow}\n",
    ")\n",
    "try:\n",
    "return float(eval(expression, allowed))\n",
    "except Exception as e:\n",
    "return f\"Error: {str(e)}\"\n",
    "\n",
    "# Create and register tools manually\n",
    "\n",
    "solve_tool = Tool(name=\"solve_equation\", description=\"Solve algebraic equations\", func=solve_equation_func)\n",
    "explain_tool = Tool(name=\"explain_concept\", description=\"Explain math concepts\", func=explain_concept_func)\n",
    "calc_tool = Tool(name=\"math_calculate\", description=\"Calculate expressions\", func=math_calculate_func)\n",
    "\n",
    "math_registry.register(solve_tool)\n",
    "math_registry.register(explain_tool)\n",
    "math_registry.register(calc_tool)\n",
    "\n",
    "# Create math tutor agent with verbose=True to see what's happening\n",
    "\n",
    "math_tutor = Agent(llm=client, tools=math_registry, max_steps=6, verbose=True)\n",
    "\n",
    "# Test the math tutor\n",
    "\n",
    "question = \"Can you explain what a derivative is and then solve the equation 2x + 5 = 15?\"\n",
    "print(\"Question:\", question)\n",
    "print(\"\\n\" + \"=\"\\*50 + \"\\n\")\n",
    "\n",
    "answer = math_tutor.run(question)\n",
    "print(f\"\\nFinal Answer: {answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     42\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# Create math tutor agent\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m math_tutor = Agent(llm=\u001b[43mclient\u001b[49m, tools=math_registry, max_steps=\u001b[32m4\u001b[39m)\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# Test the math tutor\u001b[39;00m\n\u001b[32m     49\u001b[39m question = (\n\u001b[32m     50\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mCan you explain what a derivative is and then solve the equation 2x + 5 = 15?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     51\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a specialized math tutor agent with its own registry",
    "# Create a fresh registry each time to allow re-running",
    "math_registry = ToolRegistry()",
    "",
    "# Define functions first (without decorator)",
    "def solve_equation_func(equation: str) -> str:",
    "    \"\"\"Solve algebraic equations step by step.\"\"\"",
    "    # Mock implementation",
    "    steps = [",
    "        f\"Given: {equation}\",",
    "        \"Step 1: Isolate the variable\",",
    "        \"Step 2: Simplify both sides\",",
    "        \"Step 3: Solve for x\",",
    "        \"Solution: x = 5\",",
    "    ]",
    "    return \"\\n\".join(steps)",
    "",
    "def explain_concept_func(concept: str) -> str:",
    "    \"\"\"Explain a mathematical concept.\"\"\"",
    "    explanations = {",
    "        \"derivative\": \"The derivative measures the rate of change of a function.\",",
    "        \"integral\": \"The integral represents the area under a curve.\",",
    "        \"limit\": \"A limit describes the value a function approaches as input approaches a point.\",",
    "    }",
    "    return explanations.get(concept.lower(), f\"Explanation of {concept}...\")",
    "",
    "def math_calculate_func(expression: str) -> float:",
    "    \"\"\"Evaluate a mathematical expression.\"\"\"",
    "    # Safe evaluation",
    "    allowed = {\"__builtins__\": {}}",
    "    allowed.update(",
    "        {\"abs\": abs, \"round\": round, \"min\": min, \"max\": max, \"sum\": sum, \"pow\": pow}",
    "    )",
    "    try:",
    "        return float(eval(expression, allowed))",
    "    except Exception as e:",
    "        return f\"Error: {str(e)}\"",
    "",
    "# Create and register tools manually",
    "solve_tool = Tool(name=\"solve_equation\", description=\"Solve algebraic equations\", func=solve_equation_func)",
    "explain_tool = Tool(name=\"explain_concept\", description=\"Explain math concepts\", func=explain_concept_func)",
    "calc_tool = Tool(name=\"math_calculate\", description=\"Calculate expressions\", func=math_calculate_func)",
    "",
    "math_registry.register(solve_tool)",
    "math_registry.register(explain_tool)",
    "math_registry.register(calc_tool)",
    "",
    "# Create math tutor agent with verbose=True to see what's happening",
    "math_tutor = Agent(llm=client, tools=math_registry, max_steps=6, verbose=True)",
    "",
    "# Test the math tutor",
    "question = \"Can you explain what a derivative is and then solve the equation 2x + 5 = 15?\"",
    "print(\"Question:\", question)",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")",
    "",
    "answer = math_tutor.run(question)",
    "print(f\"\\nFinal Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Advanced Features <a id='advanced'></a>\n",
    "\n",
    "Let's explore some advanced patterns and techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Async Operations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "\n",
    "async def async_example():\n",
    "    \"\"\"Demonstrate async operations.\"\"\"\n",
    "    # Async completion\n",
    "    messages = [Message(role=Role.USER, content=\"Tell me a joke\")]\n",
    "    response = await client.acomplete(messages)\n",
    "    print(f\"Async response: {response.content}\")\n",
    "\n",
    "    # Async streaming\n",
    "    print(\"\\nAsync streaming:\")\n",
    "    async for token in client.astream(messages):\n",
    "        print(token, end=\"\", flush=True)\n",
    "    print()\n",
    "\n",
    "    # Async chain\n",
    "    chain = Chain(client).add_user(\"What is 2+2?\")\n",
    "    result = await chain.arun()\n",
    "    print(f\"\\nAsync chain result: {result}\")\n",
    "\n",
    "\n",
    "# Run async example\n",
    "await async_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom LLM Clients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ailib.core import LLMClient, CompletionResponse\n",
    "from typing import List, Iterator, AsyncIterator, Optional, Any, Dict\n",
    "\n",
    "\n",
    "class MockLLMClient(LLMClient):\n",
    "    \"\"\"A mock LLM client for testing.\"\"\"\n",
    "\n",
    "    def __init__(self, model: str = \"mock-model\"):\n",
    "        super().__init__(model)\n",
    "        self.responses = {\n",
    "            \"greeting\": \"Hello! How can I help you today?\",\n",
    "            \"math\": \"The answer is 42.\",\n",
    "            \"default\": \"I understand your question.\",\n",
    "        }\n",
    "\n",
    "    def complete(self, messages: List[Message], **kwargs) -> CompletionResponse:\n",
    "        # Simple keyword matching\n",
    "        last_message = messages[-1].content.lower()\n",
    "\n",
    "        if \"hello\" in last_message or \"hi\" in last_message:\n",
    "            response = self.responses[\"greeting\"]\n",
    "        elif \"math\" in last_message or \"calculate\" in last_message:\n",
    "            response = self.responses[\"math\"]\n",
    "        else:\n",
    "            response = self.responses[\"default\"]\n",
    "\n",
    "        return CompletionResponse(\n",
    "            content=response,\n",
    "            model=self.model,\n",
    "            usage={\"prompt_tokens\": 10, \"completion_tokens\": 5, \"total_tokens\": 15},\n",
    "        )\n",
    "\n",
    "    async def acomplete(self, messages: List[Message], **kwargs) -> CompletionResponse:\n",
    "        return self.complete(messages, **kwargs)\n",
    "\n",
    "    def stream(self, messages: List[Message], **kwargs) -> Iterator[str]:\n",
    "        response = self.complete(messages, **kwargs)\n",
    "        for char in response.content:\n",
    "            yield char\n",
    "\n",
    "    async def astream(self, messages: List[Message], **kwargs) -> AsyncIterator[str]:\n",
    "        response = self.complete(messages, **kwargs)\n",
    "        for char in response.content:\n",
    "            yield char\n",
    "\n",
    "\n",
    "# Test the mock client\n",
    "mock_client = MockLLMClient()\n",
    "response = mock_client.complete([Message(role=Role.USER, content=\"Hello there!\")])\n",
    "print(f\"Mock response: {response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReAct prompt helper\n",
    "tools = [\"search\", \"calculator\", \"weather\"]\n",
    "messages = create_react_prompt(\n",
    "    question=\"What's the population of Paris multiplied by 2?\", tools=tools\n",
    ")\n",
    "\n",
    "print(\"ReAct Prompt:\")\n",
    "for msg in messages:\n",
    "    print(f\"\\n[{msg.role.value}]:\\n{msg.content[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few-shot learning helper\n",
    "examples = [\n",
    "    {\"input\": \"happy\", \"output\": \"sad\"},\n",
    "    {\"input\": \"big\", \"output\": \"small\"},\n",
    "    {\"input\": \"hot\", \"output\": \"cold\"},\n",
    "]\n",
    "\n",
    "messages = create_few_shot_prompt(\n",
    "    instruction=\"Find the opposite word\", examples=examples, query=\"fast\"\n",
    ")\n",
    "\n",
    "print(\"Few-shot Prompt:\")\n",
    "for i, msg in enumerate(messages):\n",
    "    print(f\"{i+1}. [{msg.role.value}]: {msg.content}\")\n",
    "\n",
    "# Get completion\n",
    "response = client.complete(messages)\n",
    "print(f\"\\nAnswer: {response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Real-World Examples <a id='examples'></a>\n",
    "\n",
    "Let's build some practical applications using AILib.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Code Documentation Generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_doc_generator():\n",
    "    \"\"\"Build a code documentation generator.\"\"\"\n",
    "\n",
    "    # Create a documentation template\n",
    "    doc_template = PromptTemplate(\n",
    "        \"\"\"\n",
    "Generate comprehensive documentation for this {language} code:\n",
    "\n",
    "```{language}\n",
    "{code}\n",
    "```\n",
    "\n",
    "Include:\n",
    "1. Brief description\n",
    "2. Parameters/Arguments\n",
    "3. Return value\n",
    "4. Example usage\n",
    "\"\"\"\n",
    "    )\n",
    "\n",
    "    # Create a chain for generating docs\n",
    "    doc_chain = (\n",
    "        Chain(client)\n",
    "        .add_system(\"You are a technical documentation expert.\")\n",
    "        .add_template(doc_template, language=\"Python\", code=\"{code}\")\n",
    "    )\n",
    "\n",
    "    return doc_chain\n",
    "\n",
    "\n",
    "# Test the doc generator\n",
    "doc_gen = build_doc_generator()\n",
    "\n",
    "sample_code = \"\"\"\n",
    "def fibonacci(n: int) -> int:\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    return fibonacci(n-1) + fibonacci(n-2)\n",
    "\"\"\"\n",
    "\n",
    "documentation = doc_gen.run(code=sample_code)\n",
    "print(\"Generated Documentation:\")\n",
    "print(documentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Interactive Tutoring System\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TutoringSystem:\n",
    "    \"\"\"An interactive tutoring system using AILib.\"\"\"\n",
    "\n",
    "    def __init__(self, subject: str):\n",
    "        self.subject = subject\n",
    "        self.session = Session()\n",
    "        self.client = OpenAIClient(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "        # Initialize session\n",
    "        self.session.add_system_message(\n",
    "            f\"\"\"You are an expert {subject} tutor.\n",
    "            Adapt your explanations to the student's level.\n",
    "            Ask follow-up questions to ensure understanding.\"\"\"\n",
    "        )\n",
    "\n",
    "        # Track progress\n",
    "        self.session.set_memory(\"topics_covered\", [])\n",
    "        self.session.set_memory(\"student_level\", \"unknown\")\n",
    "\n",
    "    def ask_question(self, question: str) -> str:\n",
    "        \"\"\"Process a student question.\"\"\"\n",
    "        # Add question to session\n",
    "        self.session.add_user_message(question)\n",
    "\n",
    "        # Get response\n",
    "        response = self.client.complete(self.session.get_messages())\n",
    "        self.session.add_assistant_message(response.content)\n",
    "\n",
    "        # Update topics covered\n",
    "        topics = self.session.get_memory(\"topics_covered\")\n",
    "        if question.lower() not in str(topics).lower():\n",
    "            topics.append(question[:50])  # Store first 50 chars\n",
    "            self.session.set_memory(\"topics_covered\", topics)\n",
    "\n",
    "        return response.content\n",
    "\n",
    "    def get_summary(self) -> str:\n",
    "        \"\"\"Get a summary of the tutoring session.\"\"\"\n",
    "        topics = self.session.get_memory(\"topics_covered\")\n",
    "\n",
    "        summary_prompt = f\"\"\"\n",
    "        Based on our conversation, provide a brief summary of:\n",
    "        1. Topics we covered: {topics}\n",
    "        2. Key concepts explained\n",
    "        3. Suggested next steps for the student\n",
    "        \"\"\"\n",
    "\n",
    "        self.session.add_user_message(summary_prompt)\n",
    "        response = self.client.complete(self.session.get_messages())\n",
    "\n",
    "        return response.content\n",
    "\n",
    "\n",
    "# Create a math tutor\n",
    "tutor = TutoringSystem(\"Mathematics\")\n",
    "\n",
    "# Simulate a tutoring session\n",
    "print(\"=== Math Tutoring Session ===\")\n",
    "print()\n",
    "\n",
    "response1 = tutor.ask_question(\"What is calculus?\")\n",
    "print(\"Student: What is calculus?\")\n",
    "print(f\"Tutor: {response1[:300]}...\\n\")\n",
    "\n",
    "response2 = tutor.ask_question(\"Can you give me an example of a derivative?\")\n",
    "print(\"Student: Can you give me an example of a derivative?\")\n",
    "print(f\"Tutor: {response2[:300]}...\\n\")\n",
    "\n",
    "# Get session summary\n",
    "print(\"=== Session Summary ===\")\n",
    "summary = tutor.get_summary()\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Research Assistant Agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a research assistant with custom tools and registry\n",
    "research_registry = ToolRegistry()\n",
    "\n",
    "\n",
    "@tool(registry=research_registry)\n",
    "def analyze_topic(topic: str) -> str:\n",
    "    \"\"\"Analyze a research topic and identify key areas.\"\"\"\n",
    "    return f\"\"\"\n",
    "    Analysis of '{topic}':\n",
    "    - Main concepts: [Key concepts related to {topic}]\n",
    "    - Research areas: [Current research directions]\n",
    "    - Applications: [Practical applications]\n",
    "    - Challenges: [Open problems and challenges]\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "@tool(registry=research_registry)\n",
    "def find_papers(topic: str, year_start: int = 2020) -> str:\n",
    "    \"\"\"Find relevant research papers on a topic.\"\"\"\n",
    "    # Mock implementation\n",
    "    papers = [\n",
    "        f\"'{topic}: A Comprehensive Survey' (2023) - Smith et al.\",\n",
    "        f\"'Advances in {topic}' (2022) - Johnson & Lee\",\n",
    "        f\"'Future Directions for {topic}' (2024) - Brown et al.\",\n",
    "    ]\n",
    "    return \"Relevant papers:\\n\" + \"\\n\".join(f\"- {p}\" for p in papers)\n",
    "\n",
    "\n",
    "@tool(registry=research_registry)\n",
    "def summarize_findings(papers: str, focus: str = \"general\") -> str:\n",
    "    \"\"\"Summarize research findings.\"\"\"\n",
    "    return f\"\"\"\n",
    "    Summary of findings (focus: {focus}):\n",
    "    1. Current state of the field shows significant progress\n",
    "    2. Key innovations include new methodologies and applications\n",
    "    3. Future work should address scalability and practical deployment\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "# Add the search tool to research registry\n",
    "@tool(name=\"research_search\", registry=research_registry)\n",
    "def research_search(query: str, max_results: int = 3) -> str:\n",
    "    \"\"\"Perform a web search for research.\"\"\"\n",
    "    # Mock implementation\n",
    "    results = [f\"Result {i+1}: Research about {query}\" for i in range(max_results)]\n",
    "    return \"\\n\".join(results)\n",
    "\n",
    "\n",
    "# Create research assistant\n",
    "research_assistant = Agent(\n",
    "    llm=OpenAIClient(model=\"gpt-4\"), tools=research_registry, max_steps=6\n",
    ")\n",
    "\n",
    "# Conduct research\n",
    "research_query = \"\"\"\n",
    "I need to research 'quantum computing applications in cryptography'.\n",
    "Please analyze the topic, find relevant papers from 2022 onwards,\n",
    "and summarize the key findings focusing on practical applications.\n",
    "\"\"\"\n",
    "\n",
    "print(\"=== Research Assistant ===\")\n",
    "research_result = research_assistant.run(research_query)\n",
    "print(f\"\\nResearch Summary:\\n{research_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook has demonstrated the comprehensive features of AILib:\n",
    "\n",
    "1. **Simple API**: Intuitive interfaces for all components\n",
    "2. **Flexibility**: From basic completions to complex agents\n",
    "3. **Extensibility**: Easy to add custom tools and clients\n",
    "4. **Type Safety**: Full type hints throughout\n",
    "5. **Production Ready**: Sessions, error handling, and async support\n",
    "\n",
    "AILib provides a cleaner, more Pythonic alternative to existing frameworks while maintaining powerful capabilities for building LLM applications.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Explore the remaining low-priority features (validation, safety, tracing)\n",
    "- Build your own custom tools and agents\n",
    "- Integrate with your existing applications\n",
    "- Contribute to the project on GitHub\n",
    "\n",
    "Happy building with AILib! \ud83d\ude80\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
